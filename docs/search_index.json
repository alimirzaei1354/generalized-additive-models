[["index.html", "Generalized Additive Models", " Generalized Additive Models Michael Clark m-clark.github.io "],["preface.html", "Preface", " Preface The following provides a brief introduction to generalized additive models and some thoughts on getting started with R. It doesn’t assume much more than a basic exposure to regression, and maybe a general idea of R, though not necessarily any particular expertise. The presentation is of a very applied nature, and such that the topics build upon the familiar and generalize to the less so, with the hope that one can bring the concepts they are comfortable with to the new material. The audience in mind is anyone that has some data modeling background and would like to learn more about this type of model. As this document is more conceptual, a basic familiarity with R is all that is needed to follow the code, though there is much to be gained from having more familiarity. One should also note that the tidyverse is used throughout for any data processing that might be shown depicted. And while it wasn’t the intention starting out, this document could be seen as a vignette for the mgcv package, which is highly recommended. The content of this document is heavily indebted to the first and second editions of Wood’s GAM book, and I’ve tried to keep things up to date with both the package and text. Color guide: important term link package function object or class Packages to note: data processing tidyverse models mgcv lme4 * mixedup *† gratia * visualization plotly * visibly *† ggeffects * gratia * * demo and/or not required † Personal package Many others are used behind the scenes. In addition, I do a lot of cleanup for visualizations in general. R Info: R version 4.2.1 (2022-06-23) Funny-Looking Kid This document was last modified 2022-07-16. Original draft August 2012. (@$%* me I’ve been doing this stuff a while). "],["introduction.html", "Introduction Beyond the General Linear Model I Beyond the General Linear Model II Summary", " Introduction Beyond the General Linear Model I General Linear Model Let’s get started by considering the standard linear regression model (SLiM) estimated via ordinary least squares (OLS). We have some response or target variable we wish to study, and believe it to be some function of other variables. In terms of the underlying data generating process, \\(y\\) is the variable of interest, assumed to be normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\), and the Xs are the features/covariates in this scenario. The features are multiplied by the weights/coefficients (\\(\\beta\\)) and summed, giving us the linear predictor, which in this case also directly provides us the estimated fitted values. The following is a variant of the way this type of model is presented in introductory texts. \\[y\\sim \\mathcal{N}(\\mu,\\sigma^2)\\] \\[\\mu = b_0+b_1\\cdot x_1+b_2\\cdot x_2\\;...\\;+ b_p\\cdot x_p\\] Here is an example of how the R code would look like for such a model. mymod = lm(y ~ x1 + x2, data = mydata) One of the issues with this model is that, in its basic form it can be very limiting in its assumptions about the data generating process for the variable we want to study. It also very typically will not capture what is going on in a great many data situations. Generalized Linear Model In that light, we may consider the generalized linear model. Generalized linear models incorporate other types of distributions1, and include a link function \\(g(.)\\) relating the mean \\(\\mu\\), or stated differently, the expected values \\(E(y)\\), to the linear predictor \\(X\\beta\\), often denoted \\(\\eta\\). So the general form is: \\[g(\\mu) = \\eta = X\\beta\\] \\[E(y) = \\mu = g^{-1}(\\eta)\\] Consider again the typical linear regression. In that situation, we assume a Gaussian (i.e. normal) distribution for the response, we assume equal variance for all observations, and that there is a direct link of the linear predictor and the expected value \\(\\mu\\), i.e. \\(\\mu = X\\beta\\). As such, the typical linear regression model is a generalized linear model with a Gaussian distribution and ‘identity’ link function. To further illustrate the generalization, we consider a distribution other than the Gaussian. Here we’ll examine a Poisson distribution for some vector of count data. There is only one parameter to be considered, \\(\\mu\\), since for the Poisson the mean and variance are equal. For the Poisson, the (canonical) link function \\(g(.)\\), is the natural log, and so relates the log of \\(\\mu\\) to the linear predictor. As such we could also write it in terms of exponentiating the right-hand side. \\[y \\sim \\mathcal{P}(\\mu)\\] \\[\\ln(\\mu) = b_0+b_1\\cdot x_1+b_2\\cdot x_2\\;...\\;+ b_p\\cdot x_p\\] \\[\\mu = e^{b_0+b_1\\cdot x_1+b_2\\cdot x_2\\;...\\;+b_p\\cdot x_p}\\] While there is a great deal to further explore with regard to generalized linear models, the point here is to simply to note them as a generalization of the typical linear model that we would all be familiar after an introductory course in modeling/statistics. As we eventually move to generalized additive models, we can see them as a subsequent step in the generalization. Generalized Additive Model Now let us make another generalization to incorporate nonlinear forms of the features, via a generalized additive model. This form gives the new setup relating our new, now nonlinear predictor to the expected value, with whatever link function may be appropriate. \\[ y \\sim ExpoFam(\\mu, etc.) \\\\ E(y) = \\mu \\\\ g(\\mu) = b_0 + f(x_1) + f(x_2) \\;...\\;+f(x_p) \\] So what’s the difference? In short, we are using smooth functions of our feature variables, which can take on a great many forms, with more detail on what that means in the following section. For now, it is enough to note the observed values \\(y\\) are assumed to be of some exponential family distribution, and \\(\\mu\\) is still related to the model predictors via a link function. The key difference is that the linear predictor now incorporates smooth functions of at least some (possibly all) features, represented as \\(f(x)\\), and this will allow for nonlinear relationships between the features and the target variable \\(y\\). Beyond the General Linear Model II Fitting the Standard Linear Model In many data situations, the relationship between some covariate(s) \\(X\\) and response \\(y\\) is not so straightforward. Consider the following plot. Attempting to fit a standard OLS regression results in the blue line, which doesn’t capture the relationship as well as we would like. Polynomial Regression One common approach we could undertake is to add a transformation of the predictor \\(X\\), and in this case we might consider a quadratic term such that our model looks something like the following. \\[ y \\sim \\mathcal{N}(\\mu,\\sigma^2)\\\\ \\mu = b_0 + b_1\\cdot x_1+b_2\\cdot x_1^2 \\] And here is how the model would fit the data. We haven’t really moved from the standard linear model in this case, but we have a much better fit to the data as evidenced by the graph. Scatterplot Smoothing There are still other possible routes we could take. Many are probably familiar with loess (or lowess) regression, if only in the sense that often statistical packages may, either by default or with relative ease, add a nonparametric fit line to a scatterplot. By default, this is typically lowess, or locally weighted scatterplot smoothing. Take a look at the following figure. For every (sorted) \\(x_0\\) value, we choose a neighborhood around it and, for example, fit a simple regression. As an example, let’s look at \\(x_0\\) = 3.0, and choose a neighborhood of 100 X values below and 100 values above. Now, for just that range we fit a linear regression model and note the fitted value where \\(x_0=3.0\\). If we now do this for every \\(x_0\\) value, we’ll have fitted values based on a rolling neighborhood that is relative to each value being considered. Other options we could throw into this process, and usually do, would be to fit a polynomial regression for each neighborhood, and weight observations the closer they are to the value, with less weight given to more distant observations. The above plot shows the result from such a fitting process. For comparison, the regular regression fit is also provided. Even without using a lowess approach, we could have fit have fit a model assuming a quadratic relationship, \\(y = x + x^2\\), and it would result in a far better fit than the simpler model2. While polynomial regression might suffice in some cases, the issue is that nonlinear relationships are generally not specified so easily, as we’ll see next3. Generalized Additive Models The next figure regards a data set giving a series of measurements of head acceleration in a simulated motorcycle accident4. Time is in milliseconds, acceleration in g. Here we have data that are probably not going to be captured with simple transformations of the predictors. We can compare various approaches, and the first is a straightforward cubic polynomial regression, which unfortunately doesn’t help us much. We could try higher orders, which would help, but in the end we will need something more flexible, and generalized additive models can help us in such cases. Summary Let’s summarize our efforts up to this point. Standard Linear Model \\[y\\sim \\mathcal{N}(\\mu, \\sigma^2)\\] \\[\\mu = b_0+b_1\\cdot x_1\\] Polynomial Regression \\[y\\sim \\mathcal{N}(\\mu, \\sigma^2)\\] \\[\\mu = b_0+b_1\\cdot x_1+b_2\\cdot x^2\\] GLM formulation \\[y\\sim \\mathcal{N}(\\mu, \\sigma^2)\\] \\[g(\\mu) = b_0+b_1\\cdot x_1+b_2\\cdot x_2\\] GAM formulation \\[y\\sim \\mathcal{N}(\\mu, \\sigma^{2})\\] \\[g(\\mu) = f(X)\\] Now that some of the mystery will hopefully have been removed, let’s take a look at GAMs in action. References "],["case_for_gam.html", "The case for GAMs Why not just use standard methods? Heteroscedasticity, non-normality etc. Polynomial Regression", " The case for GAMs Why not just use standard methods? We have seen that GAMs generalize our typical approaches, but can they really help? The standard linear model is ubiquitous in statistical training and application, and for good reason. It is simple to do and easy to understand. Let’s go ahead and do one to get things started with some simulated data. mod = lm(y ~ x1 + x2, data = dat) summary(mod)   Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.3 0.3 21.8 0 x1 6.4 0.4 14.6 0 x2 -5.1 0.5 -11.3 0 Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 400 2.532 0.4594 0.4567 Everything is nice and tidy. We have straightforward information, positive effect of x1, negative for x2, and familiar output. Depending on your context, the R2 may or may not be something exciting. Let’s look at some diagnostics5. Some issues might be present, as we might be getting a little more variance with some, especially higher, fitted values. We’re also a little loose in the tails of the distribution of the residuals. Let’s compare our predictions to the data. With a strong model, we might see a cigar shaped cloud converging to a line with slope 1 as the fit gets better. We seem to be having some issues here, as the previous residual plot seemed to indicate. Now let’s go back and visualize the data. The following plots both features against the target variable. Yikes. We certainly have a positive effect for x1, but it looks rather curvy. The other feature doesn’t appear to have a relationship that could be classified as easily. It is sharply positive for low values of x2, but negative thereafter. Heteroscedasticity, non-normality etc. In many cases as above, people have some standby methods for dealing with the problem. For example, they might see the qq-plot for the residuals and think some of those cases are ‘outliers’, perhaps even dropping them from analysis. Others might try a transformation of the target variable, for example, in cases of heteroscedasticity (not because of non-normality!) some might take the log. modlog = lm(log(y) ~ x1 + x2, dat) summary(modlog)   Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.83 0.05 33.84 0 x1 0.94 0.07 13.29 0 x2 -0.69 0.07 -9.37 0 Fitting linear model: log(y) ~ x1 + x2 Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 400 0.4102 0.3968 0.3937 Well, our fit in terms of R2 has actually gone down. Let’s check the diagnostics. The transformation may have helped in some ways, but made other things worse. We continue to see some poor fitting cases and now our fit is flattening even more than it was. This is a fairly typical result. Transformations often exacerbate data issues or fail to help. What’s more, some of them lead to more difficult interpretation, or aren’t even applicable (e.g. categorical, ordinal targets). Outliers, if there was actually a standard for deeming something as such, are just indications that your model doesn’t capture the data generating process in some fashion. Cutting data out of the modeling process for that reason hasn’t been acceptable for a long time (if it ever was). Data abounds where a standard linear model performs poorly or doesn’t do a good enough job capturing the nuances of the data. There may be nonlinear relationships as above, dependency in the observations, known non-Gaussian data etc. One should be prepared to use models better suited to the situation, rather than torturing the data to fit a simplified modeling scheme. Polynomial Regression A common application in regression to deal with nonlinear relationships involves polynomial regression. For the feature in question, \\(x\\), we add terms e.g. quadratic (\\(x^2\\)), cubic (\\(x^3\\)) etc. to get a better fit. Consider the following data situation. Let’s fit a quadratic term and note the result. mod_poly = lm(y ~ poly(x, 2)) The R2 for this is 0.78, that’s great! But look closely and you might notice that we aren’t capturing the lower tail of this target at all, and not doing so great for observations that are very high on both variables. Here’s what the data and fit would look like if we extend the data based on the underlying true function, and things only get worse. Part of the reason is that, outside of deterministic relationships due to known physical or other causes, you are unlikely to discover a quadratic relationship between variables among found data. Even when it appears to fit, without a lot of data it is almost certainly overfit due to this reason. Fitting a polynomial is more akin to enforcing our vision of how the data should be, rather than letting the data speak for itself. Sure, it might be a good approximation some of the time, just as assuming a linear relationship is, but often it’s just wishful thinking. Compare the previous result to the following fit from a generalized additive model. GAMs are susceptible to extrapolation, as is every statistical model ever created. However, the original fit (in red) is much better. Notice how it was better able to follow the straightened-out data points at the high end, rather than continuing the bend that the quadratic approach enforced. A more complex relationship Perhaps you would have been satisfied with the initial quadratic fit above or perhaps a cubic fit6. We may come across a situation where the target of interest \\(y\\) is a function of some covariate \\(x\\), whose effect is not straightforward at all. Consider the following functional form for x: \\[f(x) = sin(2(4x-2)) + 2e^{-(16^2)(x-.5)^2} + \\epsilon\\] \\[\\epsilon \\sim N(0,.3^2)\\] Let’s generate some data and take a look at it visually. set.seed(123) x = runif(500) mu = sin(2 * (4 * x - 2)) + 2 * exp(-(16 ^ 2) * ((x - .5) ^ 2)) y = rnorm(500, mu, .3) d = data.frame(x, y) Polynomial regression is problematic A standard linear regression is definitely not going to capture this relationship. As above, we could try and use polynomial regression here, e.g. fitting a quadratic or cubic function within the standard regression framework. However, this is unrealistic at best, and at worst, isn’t useful for complex relationships. In the following, even with a polynomial of degree 15 the fit is fairly poor in many areas, and ‘wiggles’ in some places where there doesn’t appear to be a need to. You can (double) click to isolate specific fits. The same would hold true for other approaches that require the functional form to be specified (e.g. so-called logistic growth curve models). It’s maybe also obvious that a target transformation (e.g. log) isn’t going to help us in this case either. In general, we’ll need tools better suited to more complex relationships, or simply ones that don’t require us to overfit/simplify the relationship we see, or guess about the form randomly until finding a decent fit. In case you are wondering, yes, these diagnostic plots are in fact base R graphics, and they still can look good with some work.↩︎ The example was actually generated with a cubic polynomial.↩︎ "],["building_gam.html", "Building up to GAMs Piecewise polynomial What is a GAM? Polynomial spline", " Building up to GAMs Piecewise polynomial So how might we solve the problem we saw with polynomial regression? One way would be to divide the data into chunks at various points (knots), and fit a linear regression or polynomial model within that subset of data. The following fits a cubic polynomial for each 10 evenly divided subsets of x. While this is notably better fit than e.g., a cubic polynomial, again it is unsatisfactory. The separate fits are unconnected, leading to sometimes notably different predictions for values close together. Being fit to small amounts of data means each model overfits that area of data, leading to a fairly ‘wiggly’ result most of the time. What is a GAM? In essence, a GAM is a GLM. What distinguishes it from the ones you know is that, unlike a standard GLM, it is composed of a sum of smooth functions of features instead of or in addition to the standard linear feature contributions. Consider the standard (g)lm7: \\[y = b_0 + b_1\\cdot x\\] In the above, \\(y\\) is our target, \\(x\\) the feature variable, the coefficients are \\(b\\) and \\(\\epsilon\\) the error. For the GAM, we can specify it generally as follows: \\[y = f(x) + \\epsilon\\] Now we are dealing with some specific (additive) function of inputs, which will not require the (possibly transformed) \\(y\\) to be a linear function of \\(x\\). It involves choosing a basis, which in technical terms means choosing a space of functions for which \\(f\\) is some element of it. On the practical side, it is a means to capture nonlinear relationships. As we’ll see later, an example would be choosing a cubic spline for the basis. Choosing a basis also means we’re selecting basis functions, which will actually go into the analysis. We can add more detail as follows: \\[y = f(x) + \\epsilon = \\sum_{j=1}^{d}F_j(x)\\beta_j + \\epsilon\\] Above, each \\(F_j\\) is a basis function that is the transformed \\(x\\) depending on the type of basis considered, and the \\(b\\) are the corresponding regression coefficients. This might sound complicated, until you realize you’ve done this before! Let’s go back to the quadratic polynomial, which we can now say uses the polynomial basis. \\[f(x) = b_0 + b_1\\cdot x^1 \\ldots +b_d\\cdot x^d\\] In our previous case, \\(d=2\\) and we have our standard regression with a quadratic term, but in fact, we can use this approach to produce the bases for any polynomial. As far as mechanics go, these basis functions become extra columns in the data, just like your \\(x^2\\) etc. from the polynomial approach, and then you just run a GLM! However, an additional aspect is that we will use penalized estimation, something that is quite common in some modeling contexts like machine learning applications (but not common enough in other areas). For those new to penalized regression, again consider a standard GLM that we usually estimate with maximum likelihood, where the likelihood corresponding to the estimated coefficients \\(l(\\beta)\\), where \\(\\beta\\) are the associated regression coefficients. Conceptually we can write the penalized likelihood as follows: \\[l_p(\\beta)= l(\\beta) - \\color{darkred}{\\mathcal{penalty}}\\] If you prefer least squares as the loss function, we can put it as: \\[\\mathcal{Loss} = \\sum (y-X\\beta)^2 + \\color{darkred}{\\mathcal{penalty}}\\] The penalty regards the complexity of the model, and specifically the size of the coefficients for the smooth terms. The practical side is that it will help to keep us from overfitting the data, where our smooth function might get too wiggly8. In summary, you’re doing a GLM, but a slightly modified one. You could have always been using penalized GLM (e.g. lasso or ridge regression), and you’d have slightly better predictive capability if you had. We can use different loss functions, different penalties etc., but the concepts are the main thing to note here. For a little more detail on this section visit the technical section. Polynomial spline Let’s get things started by demonstrating the results from a GAM that uses a polynomial spline for the basis. The brave may refer to the technical details section for additional insights. Conceptually, it is useful to continue to think of the piecewise approach we talked about before. However, we’ll end up with a smoother and connected result when all is said and done. Very nice! This is much better. We now have a connected result that isn’t overly wiggly, and more importantly, actually fits the data quite well. I am leaving out subscripts where I don’t think it helps, and as these are conceptual depictions, they usually don’t.↩︎ Wiggly is a highly technical term I will use throughout the presentation.↩︎ "],["application.html", "Application Using R Initial Examination Single Feature Multiple Features", " Application Using R We’re now ready to do some modeling! We’ve now seen the relationships of GAM to techniques we know, deficiencies with common approaches, and a little bit about how GAMs work conceptually. The next step is to dive in. Initial Examination The data set has been constructed using average Science scores by country from the Programme for International Student Assessment (PISA) 2006, along with GNI per capita (Purchasing Power Parity, 2005 dollars), Educational Index, Health Index, and Human Development Index from UN data. The key variables are as follows (variable abbreviations in bold)9: Overall Science Score (average score for 15 year olds) Interest in science Identifying scientific Issues Explaining phenomena scientifically Support for scientific inquiry Income Index Health Index Education Index Human Development Index (composed of the Income index, Health Index, and Education Index) But even before we get too far, it would be good to know our options in the world of GAMs. The appendix of this document has a list of some packages to be aware of, and there is quite a bit of GAM functionality available within R, even for just plotting10. We will use mgcv for our purposes. The first thing to do is get the data in and do some initial inspections. # url for the data is: # https://raw.githubusercontent.com/m-clark/generalized-additive-models/master/data/pisasci2006.csv pisa = read_csv(&#39;data/pisasci2006.csv&#39;) @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #cnrjlpczle .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #cnrjlpczle .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #cnrjlpczle .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #cnrjlpczle .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cnrjlpczle .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #cnrjlpczle .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #cnrjlpczle .gt_column_spanner_outer:first-child { padding-left: 0; } #cnrjlpczle .gt_column_spanner_outer:last-child { padding-right: 0; } #cnrjlpczle .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #cnrjlpczle .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #cnrjlpczle .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #cnrjlpczle .gt_from_md > :first-child { margin-top: 0; } #cnrjlpczle .gt_from_md > :last-child { margin-bottom: 0; } #cnrjlpczle .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #cnrjlpczle .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #cnrjlpczle .gt_row_group_first td { border-top-width: 2px; } #cnrjlpczle .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #cnrjlpczle .gt_first_summary_row.thick { border-top-width: 2px; } #cnrjlpczle .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cnrjlpczle .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #cnrjlpczle .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #cnrjlpczle .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #cnrjlpczle .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_left { text-align: left; } #cnrjlpczle .gt_center { text-align: center; } #cnrjlpczle .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #cnrjlpczle .gt_font_normal { font-weight: normal; } #cnrjlpczle .gt_font_bold { font-weight: bold; } #cnrjlpczle .gt_font_italic { font-style: italic; } #cnrjlpczle .gt_super { font-size: 65%; } #cnrjlpczle .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #cnrjlpczle .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #cnrjlpczle .gt_asterisk { font-size: 100%; vertical-align: 0; } #cnrjlpczle .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #cnrjlpczle .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #cnrjlpczle .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } Variable N Mean SD Min Q1 Median Q3 Max % Missing Overall 57.0 473.1 54.6 322.0 428.0 489.0 513.0 563.0 12.0 Issues 57.0 469.9 53.9 321.0 427.0 489.0 514.0 555.0 12.0 Explain 57.0 475.0 54.0 334.0 432.0 490.0 517.0 566.0 12.0 Evidence 57.0 469.8 61.7 288.0 423.0 489.0 515.0 567.0 12.0 Interest 57.0 528.2 49.8 448.0 501.0 522.0 565.0 644.0 12.0 Support 57.0 512.2 26.1 447.0 494.0 512.0 529.0 569.0 12.0 Income 61.0 0.7 0.1 0.4 0.7 0.8 0.8 0.9 6.0 Health 61.0 0.9 0.1 0.7 0.8 0.9 0.9 1.0 6.0 Edu 59.0 0.8 0.1 0.5 0.7 0.8 0.9 1.0 9.0 HDI 59.0 0.8 0.1 0.6 0.7 0.8 0.9 0.9 9.0 The scatterplot matrix has quite a bit of information to spend some time with- univariate density, loess curves, and correlations. For our purposes, we will ignore the issue regarding the haves vs. have-nots on the science scale and save that for another day. Note the surprising negative correlation between interest and overall score for science, which might remind us of Simpson’s paradox, namely, that what occurs for the individual may not be the same for the group. One will also note that while there is a positive correlation between Income and Overall science scores, it flattens out after an initial rise. Linear fits might be difficult to swallow for some of these, but let’s take a closer look. We can see again that linear fits aren’t going to do so well for some, though it might be a close approximation for interest in science and support for science. Now let’s run the smooth. By default, ggplot2 will use a loess smoother for small data sets (i.e. &lt; 1000 observations), but one can use the mgcv gam function as a smoother by setting method = 'gam' in when using geom_smooth. Often in these situations people will perform some standard transformation, such as a log, but as we noted earlier, it doesn’t help as nearly as often as it is used. For example, in this case one can log the overall score, Income, or both and a linear relation will still not be seen. Single Feature Linear Fit We will start with the simple situation of using a single feature for prediction. Let’s begin by using a typical linear regression to predict science scores by the Income index. We could use the standard R lm function, but I’ll leave that as an exercise for comparison. We can still do straightforward linear models with the gam function, and again it is important to note that the standard linear model can be seen as a special case of a GAM. library(mgcv) mod_lm = gam(Overall ~ Income, data = pisa) summary(mod_lm) Family: gaussian Link function: identity Formula: Overall ~ Income Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 204.32 35.37 5.777 4.32e-07 *** Income 355.85 46.79 7.606 5.36e-10 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.518 Deviance explained = 52.7% GCV = 1504.5 Scale est. = 1448.8 n = 54 What are we getting here? The same thing you get from a regular linear model, because you just ran one. However, there are a couple things to look at. The coefficient is statistically significant, but serves as a reminder that it usually a good idea to scale feature variables so that the effect is more meaningful. Here, moving one unit on Income is akin from going broke to being the richest country. But in a more meaningful sense, if we moved from say, .7 to .8, we’d expect an increase of about 35 points on the science score. We also see the deviance explained11, which serves as a generalization of R-squared, and in this case, it actually is equivalent to the unadjusted R-squared. Likewise, there is the familiar adjusted version of it to account for small sample size and model complexity. The scale estimate is the scaled deviance, which here is equivalent to the residual sums of squares. The GCV score we will save for when we run a GAM. GAM Let’s now try some nonlinear approaches12, keeping in mind that \\(\\mu=f(x)\\). As a point of comparison, we can start by trying a standard polynomial regression, and it might do well enough, but let’s go further. To begin we must consider a basis to use, a space that \\(f\\) is an element of. Doing so leads to choosing a set of basis functions \\(F_j\\), with parameters \\(b_j\\) that will be combined to produce \\(f(x)\\): \\[f(x)=\\displaystyle\\sum\\limits_{j=1}^q F_{j}(x)b_{j}\\] To better explain by example, if we use a cubic polynomial, the basis is: \\(F_1(x) = 1\\), \\(F_2(x)=x\\), \\(F_3(x)=x^2\\), \\(F_4(x)=x^3\\), which leads to the following: \\[f(x) = b_1 + b_2\\cdot x + b_3\\cdot x^2 + b_4\\cdot x^3\\] The following visualization allows us to see the effects in action. It is based on the results extracted from running such a model13 and obtaining the coefficients. The first plot represents the intercept of 470.44, the second plot, our \\(b_2\\) coefficient of 289.5 multiplied by Income and so forth. The bottom plot shows the final fit \\(f(x)\\), i.e. the linear combination of the basis functions. At this point we have done nothing we couldn’t do in our regular regression approach, as polynomial regression has a long history of use in modeling. However, the take home message is that as we move to GAMs we are going about things in much the same fashion; we are simply changing the nature of the basis, and have a great deal more flexibility in choosing the form. In the next visualization I show the fit using a ‘by-hand’ cubic spline basis (see the Appendix and p.126-7 in S. N. Wood (2006)). A cubic spline is essentially a connection of multiple cubic polynomial regressions, similar to what we demonstrated previously. We choose points of the feature variable at which to create sections, and these points are referred to as knots. Separate cubic polynomials are fit at each section, and then joined at the knots to create a continuous curve. The above graph represents a cubic spline with 8 knots between the first and third quartiles14. The red line uses the GAM results from mgcv. Fitting the model Let’s now fit an actual generalized additive model using the same cubic spline as our basis. We again use the gam function as before for basic model fitting, but now we are using a function s within the formula to denote the smooth terms. Within that function we also specify the type of smooth, though a default is available. I chose bs = cr, denoting cubic regression splines, to keep consistent with our previous example. mod_gam1 = gam(Overall ~ s(Income, bs = &quot;cr&quot;), data = pisa) summary(mod_gam1) Family: gaussian Link function: identity Formula: Overall ~ s(Income, bs = &quot;cr&quot;) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 470.444 4.082 115.3 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value s(Income) 6.895 7.741 16.67 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.7 Deviance explained = 73.9% GCV = 1053.7 Scale est. = 899.67 n = 54 The first thing to note is that, aside from the smooth part, our model code is similar to what we’re used to with core R functions such as lm and glm. In the summary, we first see the distribution assumed, as well as the link function used, in this case normal and identity, respectively, which to iterate, had we had no smoothing, would result in a SLiM. After that we see that the output is separated into parametric and smooth, or nonparametric parts15. In this case, the only parametric component is the intercept, but it’s good to remember that you are not bound to use a smooth for every feature of interest, and indeed, as we will discuss in more detail later, part of the process may involve refitting the model with terms that were found to be linear for the most part anyway. The smooth component of our model regarding a country’s income and its relationship with overall science score suggests it is statistically significant, but there are a couple of things in the model summary that would be unfamiliar. We’ll start with the effective degrees of freedom16, or edf. In typical OLS regression the model degrees of freedom is equivalent to the number of features/terms in the model. This is not so straightforward with a GAM due to the smoothing process and the penalized regression estimation procedure, something that will be discussed more later17. In this situation, we are still trying to minimize the residual sums of squares, but we also have a built-in penalty for ‘wiggliness’ of the fit, where in general we try to strike a balance between an undersmoothed fit and an oversmoothed fit. The default p-value for the test is based on the effective degrees of freedom and the rank \\(r\\) of the covariance matrix for the coefficients for a particular smooth, so here, conceptually, it is the p-value associated with the \\(F(r, n-edf)\\). However, there are still other issues to be concerned about, and ?summary.gam will provide your first step down that particular rabbit hole. For hypothesis testing an alternate edf is actually used, which is the other one provided there in the summary result18. At this point you might be thinking these p-values are a bit fuzzy, and you’d be right. The gist is, they aren’t to be used for harsh cutoffs, say, at an arbitrary .05 level19, but if they are pretty low you can feel comfortable claiming statistical significance, which of course is the end all, be all, of the scientific endeavor- right? The GCV, or generalized cross validation score can be taken as an estimate of the mean square prediction error based on a leave-one-out cross validation estimation process. We estimate the model for all observations except \\(i\\), then note the squared residual predicting observation \\(i\\) from the model. Then we do this for all observations. However, the GCV score is an efficient measure of this concept that doesn’t actually require fitting all those models and overcomes other issues20. It is this score that is minimized by default when determining the specific nature of the smooth. On its own it doesn’t tell us much, but we can use it similar to AIC as a comparative measure to choose among different models, with lower being better. Visualization One can get sense of the form of the fit by plotting the model object as follows21: ## plot(mod_gam1) Note that the plot function will only plot the smooth terms in the model- the others are straight lines since they are linear effects. The intervals are Bayesian credible intervals based on the posterior predictive distribution. In this single feature case, one can also revisit the previous graph. Model Comparison Lets compare our regular regression fit to the GAM fit. The following shows how one can extract various measures of performance, and the subsequent table shows them gathered together. AIC(mod_lm) [1] 550.2449 summary(mod_lm)$sp.criterion GCV.Cp 1504.496 summary(mod_lm)$r.sq # adjusted R squared [1] 0.5175346 Do the same to extract those same elements from the GAM. The following display makes for easy comparison. @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #mhqesfbqwq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mhqesfbqwq .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mhqesfbqwq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mhqesfbqwq .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mhqesfbqwq .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mhqesfbqwq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mhqesfbqwq .gt_column_spanner_outer:first-child { padding-left: 0; } #mhqesfbqwq .gt_column_spanner_outer:last-child { padding-right: 0; } #mhqesfbqwq .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mhqesfbqwq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #mhqesfbqwq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mhqesfbqwq .gt_from_md > :first-child { margin-top: 0; } #mhqesfbqwq .gt_from_md > :last-child { margin-bottom: 0; } #mhqesfbqwq .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mhqesfbqwq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mhqesfbqwq .gt_row_group_first td { border-top-width: 2px; } #mhqesfbqwq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mhqesfbqwq .gt_first_summary_row.thick { border-top-width: 2px; } #mhqesfbqwq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mhqesfbqwq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mhqesfbqwq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mhqesfbqwq .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #mhqesfbqwq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_left { text-align: left; } #mhqesfbqwq .gt_center { text-align: center; } #mhqesfbqwq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mhqesfbqwq .gt_font_normal { font-weight: normal; } #mhqesfbqwq .gt_font_bold { font-weight: bold; } #mhqesfbqwq .gt_font_italic { font-style: italic; } #mhqesfbqwq .gt_super { font-size: 65%; } #mhqesfbqwq .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #mhqesfbqwq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #mhqesfbqwq .gt_asterisk { font-size: 100%; vertical-align: 0; } #mhqesfbqwq .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #mhqesfbqwq .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #mhqesfbqwq .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } model AIC GCV R^2 LM 550.24 1,504.50 0.52 GAM 529.81 1,053.73 0.70 Comparing these various measures, it’s safe to conclude that the GAM fits better. We can also perform the familiar statistical test via the anova function we apply to other R model objects. As with the previous p-value issue, we can’t get too carried away, and technically one could have a model with even more terms but lower edf, but would be difficult to interpret22. As it would be best to be conservative, we’ll proceed cautiously. anova(mod_lm, mod_gam1, test = &quot;Chisq&quot;) Analysis of Deviance Table Model 1: Overall ~ Income Model 2: Overall ~ s(Income, bs = &quot;cr&quot;) Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 52.000 75336 2 45.259 41479 6.7411 33857 2.778e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 It would appear the ANOVA results tell us what we have probably come to believe already, that incorporating nonlinear effects has improved the model considerably. Multiple Features Let’s now see what we can do with a more realistic case where we have added model complexity. Linear Fit We’ll start with the linear model approach again, this time adding the Health and Education indices. mod_lm2 = gam(Overall ~ Income + Edu + Health, data = pisa) summary(mod_lm2) Family: gaussian Link function: identity Formula: Overall ~ Income + Edu + Health Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 121.18 78.97 1.535 0.1314 Income 182.32 85.27 2.138 0.0376 * Edu 234.11 54.78 4.274 9.06e-05 *** Health 27.01 134.90 0.200 0.8421 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.616 Deviance explained = 63.9% GCV = 1212.3 Scale est. = 1119 n = 52 It appears we have statistical effects for Income and Education, but not for Health, and the adjusted R-squared suggests a notable amount of the variance is accounted for23. Let’s see about nonlinear effects. GAM As far as the generalized additive model goes, we can approach things in a similar manner as before, and now and look for nonlinear effects for each feature24. mod_gam2 = gam(Overall ~ s(Income) + s(Edu) + s(Health), data = pisa) summary(mod_gam2) Family: gaussian Link function: identity Formula: Overall ~ s(Income) + s(Edu) + s(Health) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 471.154 2.772 170 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value s(Income) 7.593 8.415 8.826 1.29e-06 *** s(Edu) 6.204 7.178 3.308 0.00771 ** s(Health) 1.000 1.000 2.736 0.10679 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.863 Deviance explained = 90.3% GCV = 573.83 Scale est. = 399.5 n = 52 There are again a couple things to take note of. First, statistically speaking, we come to the same conclusion as the linear model regarding the individual effects. One should take particular note of the effect of Health index. The effective degrees of freedom with value 1 suggests that it has essentially been reduced to a simple linear effect. The following will update the model to explicitly model the effect as linear, but as one can see based on GCV and other values, the results are identical, because the penalty had effectively rendered it linear. mod_gam2B = update(mod_gam2, . ~ . - s(Health) + Health) summary(mod_gam2B) Family: gaussian Link function: identity Formula: Overall ~ s(Income) + s(Edu) + Health Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 640.3 102.3 6.260 3.06e-07 *** Health -189.5 114.6 -1.654 0.107 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value s(Income) 7.593 8.415 8.826 1.29e-06 *** s(Edu) 6.204 7.178 3.308 0.00771 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.863 Deviance explained = 90.3% GCV = 573.83 Scale est. = 399.5 n = 52 We can also note that this model accounts for much of the variance in Overall science scores, with an adjusted R-squared of .86. In short, it looks like the living standards and educational resources of a country are associated with overall science scores, even if we don’t really need the Health index in the model. Visualization Now we examine the effects of interest visually via component plots25. The following uses my own function from visibly but you can also use packages like ggeffects or gratia. The following is close to what you’d get with the former. plot(ggeffects::ggpredict(mod_gam2), facets = TRUE) gratia::draw(mod_gam2) Here we can see the effects of interest, and again one might again note the penalized-to-linear effect of Health26. As before, we see the tapering off of Income’s effect at its highest levels, and in addition, a kind of sweet spot for a positive effect of Education in the mid-range values, with a slight positive effect overall. Health, as noted, has been reduced to a linear, surprisingly negative effect, but again this is not statistically significant. The following code demonstrates how to create data necessary for the plot, specifically for incomes, with the other features held at their mean values. See the technical section for more details on these visualizations. # Note that mod_gam2$model is the data that was used in the modeling process, # so it will have NAs removed. testdata = data.frame( Income = seq(.4, 1, length = 100), Edu = mean(mod_gam2$model$Edu), Health = mean(mod_gam2$model$Health) ) predictions = predict( mod_gam2, newdata = testdata, type = &#39;response&#39;, se = TRUE ) df_preds = data.frame(testdata, predictions) %&gt;% mutate(lower = fit - 1.96 * se.fit, upper = fit + 1.96 * se.fit) ggplot(aes(x = Income, y = fit), data = df_preds) + geom_ribbon(aes(ymin = lower, ymax = upper), fill = &#39;gray92&#39;) + geom_line(color = &#39;#56B4E9&#39;) 2d Smooths The GAM gives us a sense for one feature, but let’s now take a gander at Income and Education at the same time. Previously, we saw how to use the plot method for a GAM class object. There is another plotting function, vis.gam, that will give us a bit more to play with, and specifically to display 2d smooths. The actual plot shown provided instead depicts a heatmap with the values on the response scale. vis.gam(mod_gam2, type = &#39;response&#39;, plot.type = &#39;contour&#39;) First and foremost, the figure reflects the individual plots, and we can see high on Income generally produces the highest scores, while Education has less of an effect. Conversely, being low on both the Education and Income indices are associated with poor Overall science scores. While interesting, these respective smooths were created separately of one another, and there is another way we might examine how these two effects work together in predicting the response. So let’s take a look at another approach, continuing the focus on visualization. It may not be obvious at all, but one can utilize smooths of more than one feature, in effect, a smooth of the smooths of the variables that go into it. This is akin to an interaction in typical model settings27. Let’s create a new model to play around with this. After fitting the model, I provide both a visualization for comparison to the previous, as well as a 3D view one can interactively rotate to their liking. mod_gam3 = gam(Overall ~ te(Income, Edu), data = pisa) summary(mod_gam3) Family: gaussian Link function: identity Formula: Overall ~ te(Income, Edu) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 471.154 3.349 140.7 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value te(Income,Edu) 10.1 12.19 16.93 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.8 Deviance explained = 84% GCV = 741.42 Scale est. = 583.17 n = 52 ## vis.gam( ## mod_gam3, ## type = &#39;response&#39;, ## plot.type = &#39;persp&#39;, ## phi = 30, ## theta = 30, ## n.grid = 500, ## border = NA ## ) In the above we are using a type of smooth called a tensor product smooth, and by smoothing the marginal smooths of Income and Education, we see a bit clearer story. As we might suspect, wealthy countries with more of an apparent educational infrastructure are going to score higher on the Overall science score. However, wealth alone does not necessarily guarantee higher science scores (note the dark bottom right corner on the contour plot)28, though without at least moderate wealth hopes are fairly dim for a decent score. One can also, for example, examine interactions between a smooth and a linear term \\(f(x)z\\), and in a similar vein of thought look at smooths at different levels of a grouping factor. Model Comparison As before, we can examine indices such as GCV or perhaps adjusted R-squared, which both suggest our GAM performs considerably better. Statistically we can compare the two models with anova as before. anova(mod_lm2, mod_gam2, test = &quot;Chisq&quot;) Analysis of Deviance Table Model 1: Overall ~ Income + Edu + Health Model 2: Overall ~ s(Income) + s(Edu) + s(Health) Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 48.000 53713 2 34.408 14463 13.592 39250 6.754e-15 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Not that we couldn’t have assumed as such already, but now we have additional statistical evidence to suggest that incorporating nonlinear relationships of the features improves the model. References "],["issues.html", "Issues Estimation Choice of Smoothing Function Diagnostics Prediction Model Comparison Revisited Big Data", " Issues Here we’ll cover some additional things to consider. Estimation As noted previously, estimation of GAMs in the mgcv package is conducted via a penalized likelihood approach. More detail can be found in the technical section, but conceptually this amounts to fitting the following model: \\[g(\\mu) = f(x_1) + f(x_2) ... f(x_j)\\] But note that each smooth has its own model matrix made up of the basis functions. So for each smooth feature \\(j\\) we have: \\[f_j = \\tilde{X}_j \\tilde{\\beta}_j\\] Given a matrix of known coefficients \\(S\\), we can more formally note a penalized likelihood function: \\[l_p(\\beta)=\\displaystyle l(\\beta) - \\frac{1}{2}\\sum_j\\lambda_j \\beta^\\mathrm{T} S_j\\beta\\] where \\(l(\\beta)\\) is the usual GLM likelihood function, and \\(\\lambda_j\\) are the smoothing parameters. The part of the function including \\(\\lambda\\) penalizes curvature in the function, where \\(\\lambda\\) establishes a trade-off between the goodness of fit and the smoothness, and such an approach will allow for less overfitting. As \\(\\lambda\\rightarrow\\infty\\), we’d have a linear estimate for \\(f_j\\), while \\(\\lambda = 0\\) would allow any \\(f\\) that interpolates the data29. Technically we could specify the smoothing parameters explicitly, and the Appendix has some ‘by-hand’ code taken directly from S. N. Wood (2006) with only slight modifications, where the smoothing parameters are chosen and compared. Smoothing parameters however are in fact estimated rather than arbitrarily set, and this brings us back to the cross-validation procedure mentioned before. Smoothing parameters are selected which minimize the GCV score by default, though one has other options, e.g. using REML as with mixed models. Note that there are other approaches to estimation such as backfitting, generalized smoothing splines and Bayesian. Shrinkage &amp; Variable Selection Some smooths are such that no matter the smoothing parameter, there will always be non-zero coefficients for the basis functions. An extra penalty may be added such that if the smoothing parameter is large enough, the coefficients will shrink to zero, and some smoothing bases will have such alternative approaches available30. In this manner, one can assess whether a predictor is adding anything to the model, i.e. if it’s effective degrees of freedom is near zero, and perhaps use the approach as a variable selection technique. Choice of Smoothing Function A number of smooths are available with the mgcv package, and one can learn more via the help file for smooth.terms (link). In our models, we have used cubic regression splines and thin plate regression splines (TPRS), the latter being the default for a GAM in this package. As a brief summary, TPRS work well in general in terms of performance and otherwise has some particular advantages, and has a shrinkage alternative available. One should still feel free to play around, particularly when dealing with multiple smooths, where the tensor product smooths would be better for covariates of different scales. Diagnostics We have some built-in abilities to examine whether there are any particular issues, and we can try it with our second GAM model from the application section. gam.check(mod_gam2, k.rep = 1000) Method: GCV Optimizer: magic Smoothing parameter selection converged after 21 iterations. The RMS GCV score gradient at convergence was 2.499332e-05 . The Hessian was positive definite. Model rank = 28 / 28 Basis dimension (k) checking results. Low p-value (k-index&lt;1) may indicate that k is too low, especially if edf is close to k&#39;. k&#39; edf k-index p-value s(Income) 9.00 7.59 1.26 0.96 s(Edu) 9.00 6.20 1.01 0.44 s(Health) 9.00 1.00 0.90 0.18 This visualization is from visibly’s plot_gam_check. The plots are of the sort we’re used to from a typical regression setting, though it’s perhaps a bit difficult to make any grand conclusion based on such a small data set. The printed output on the other hand contains unfamiliar information, but is largely concerned with over-smoothing, and so has tests of whether the basis dimension for a smooth is too low. The p-values are based on simulation, so I bumped up the number with the additional argument. Guidelines are given in the output itself, and at least in this case it does not look like we have an issue. However, if there were a potential problem, it is suggested to double k parameter 31 and refit, and if the effective degrees of freedom increases quite a bit you would probably want to go with the updated model32. Given the penalization process, the exact choice of \\(k\\) isn’t too big of a deal, and can be seen as an upper limit to the flexibility of the term. The actual flexibility is determined via the penalization process. However, the defaults are arbitrary. You want to set it large enough to get at the true effect as best as possible, but in some cases computational efficiency will also be of concern. For example, in fairly complex models with many predictors, interactions, etc., it might be worthwhile to reduce \\(k\\) at the outset. The help file for the function choose.k provides another approach to examining \\(k\\) based on the residuals from the model under consideration, and provides other useful information. Concurvity Concurvity refers to the generalization of collinearity to the GAM setting33. In this case it refers to the situation where a smooth term can be approximated by some combination of the others. It largely results in the same problem as elsewhere, i.e. unstable estimates. Wood provides three indices related to concurvity via the concurvity function, all range from 0 to 1 with 0 suggesting no problem, and 1 indicating that the function lies entirely in the space of one or more of the other smooth terms. See ?concurvity for details. concurvity(mod_gam2) @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #nlrkirebmk .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nlrkirebmk .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nlrkirebmk .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nlrkirebmk .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #nlrkirebmk .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nlrkirebmk .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nlrkirebmk .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nlrkirebmk .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nlrkirebmk .gt_column_spanner_outer:first-child { padding-left: 0; } #nlrkirebmk .gt_column_spanner_outer:last-child { padding-right: 0; } #nlrkirebmk .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nlrkirebmk .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #nlrkirebmk .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nlrkirebmk .gt_from_md > :first-child { margin-top: 0; } #nlrkirebmk .gt_from_md > :last-child { margin-bottom: 0; } #nlrkirebmk .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nlrkirebmk .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #nlrkirebmk .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #nlrkirebmk .gt_row_group_first td { border-top-width: 2px; } #nlrkirebmk .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nlrkirebmk .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #nlrkirebmk .gt_first_summary_row.thick { border-top-width: 2px; } #nlrkirebmk .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nlrkirebmk .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nlrkirebmk .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nlrkirebmk .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nlrkirebmk .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #nlrkirebmk .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nlrkirebmk .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #nlrkirebmk .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nlrkirebmk .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nlrkirebmk .gt_left { text-align: left; } #nlrkirebmk .gt_center { text-align: center; } #nlrkirebmk .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nlrkirebmk .gt_font_normal { font-weight: normal; } #nlrkirebmk .gt_font_bold { font-weight: bold; } #nlrkirebmk .gt_font_italic { font-style: italic; } #nlrkirebmk .gt_super { font-size: 65%; } #nlrkirebmk .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #nlrkirebmk .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #nlrkirebmk .gt_asterisk { font-size: 100%; vertical-align: 0; } #nlrkirebmk .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #nlrkirebmk .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #nlrkirebmk .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } type para s(Income) s(Edu) s(Health) worst 0.00 0.98 0.97 0.97 observed 0.00 0.80 0.61 0.87 estimate 0.00 0.76 0.65 0.80 It should probably come as little surprise that we may have an issue here given the nature of the covariates. We can certainly make assumptions about wealthier nations’ education and health status, for example. What can we do? Collinearity does not lead to biased estimates, only less stable ones, and the inflated variance can potentially be overcome with more data. We certainly can’t do that here as we are dealing with country level data. That may also provide the solution though, since there is nothing to generalize to, as we have the population of interest (all countries with PISA scores). In other data settings however, we may need to think hard about what to include in the model to avoid such redundancy, take dimension reduction steps beforehand, or use some other selection technique. For example, if it is the result of having several time- or spatially- covarying predictors, one might be able retain only those that best capture that effect. However, the mgcv estimation procedures have been developed with such issues in mind, and one can feel fairly confident in the results even in the presence of concurvity. See Simon N. Wood (2008) for additional detail. Prediction A previous example used the predict function on the data used to fit the model to obtain fitted values on the response scale. We’d typically use this on new data. I do not cover it, because the functionality is the same as the predict.glm function in base R, and one can just refer to that. It is worth noting again that there is an option, type = 'lpmatrix', which will return the actual model matrix by which the coefficients must be pre-multiplied to get the values of the linear predictor at the supplied covariate values. This can be particularly useful towards opening the black box as one learns the technique. Model Comparison Revisited We have talked about automated smoothing parameter and term selection, and in general, potential models are selected based on estimation of the smoothing parameter. Using an extra penalty to allow coefficients to tend toward zero with the argument select = TRUE is an automatic way to go about it, where some terms could effectively drop out. Otherwise we could compare models GCV/AIC scores34, and in general, either of these would be viable approaches. Consider the following comparison: mod_1d = gam(Overall ~ s(Income) + s(Edu), data = pisa) mod_2d = gam(Overall ~ te(Income, Edu, bs = &quot;tp&quot;), data = pisa) AIC(mod_1d, mod_2d) df AIC mod_1d 15.59154 476.0631 mod_2d 13.24670 489.7046 @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #oiohuufkvv .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #oiohuufkvv .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oiohuufkvv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #oiohuufkvv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #oiohuufkvv .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oiohuufkvv .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oiohuufkvv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #oiohuufkvv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #oiohuufkvv .gt_column_spanner_outer:first-child { padding-left: 0; } #oiohuufkvv .gt_column_spanner_outer:last-child { padding-right: 0; } #oiohuufkvv .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #oiohuufkvv .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #oiohuufkvv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #oiohuufkvv .gt_from_md > :first-child { margin-top: 0; } #oiohuufkvv .gt_from_md > :last-child { margin-bottom: 0; } #oiohuufkvv .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #oiohuufkvv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #oiohuufkvv .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #oiohuufkvv .gt_row_group_first td { border-top-width: 2px; } #oiohuufkvv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oiohuufkvv .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #oiohuufkvv .gt_first_summary_row.thick { border-top-width: 2px; } #oiohuufkvv .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oiohuufkvv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oiohuufkvv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #oiohuufkvv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #oiohuufkvv .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #oiohuufkvv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oiohuufkvv .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #oiohuufkvv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oiohuufkvv .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #oiohuufkvv .gt_left { text-align: left; } #oiohuufkvv .gt_center { text-align: center; } #oiohuufkvv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #oiohuufkvv .gt_font_normal { font-weight: normal; } #oiohuufkvv .gt_font_bold { font-weight: bold; } #oiohuufkvv .gt_font_italic { font-style: italic; } #oiohuufkvv .gt_super { font-size: 65%; } #oiohuufkvv .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #oiohuufkvv .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #oiohuufkvv .gt_asterisk { font-size: 100%; vertical-align: 0; } #oiohuufkvv .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #oiohuufkvv .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #oiohuufkvv .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } model df AIC mod_1d 15.59 476.06 mod_2d 13.25 489.70 In some cases, we might prefer to be explicit in comparing models with and without particular terms, and we can go about comparing models as we would with a typical GLM analysis of deviance. We have demonstrated this previously using the anova.gam function, where we compared linear fits to a model with an additional smooth function. While we could construct a scenario that is identical to the GLM situation for a statistical comparison, it should be noted that in the usual situation the test is actually an approximation, though it should be close enough when it is appropriate in the first place. The following provides an example that would nest the main effects of Income and Education within the product smooth, i.e. sets their basis dimension and smoothing function to the defaults employed by the tensor product smooth. mod_A = gam( Overall ~ s(Income, bs = &quot;cr&quot;, k = 5) + s(Edu, bs = &quot;cr&quot;, k = 5), data = pisa ) mod_B = gam( Overall ~ ti(Income, bs = &quot;cr&quot;, k = 5) + ti(Edu, bs = &quot;cr&quot;, k = 5) + ti(Income, Edu, bs = &#39;cr&#39;), data = pisa ) anova(mod_A, mod_B, test = &quot;Chisq&quot;) @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ycisafecye .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ycisafecye .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ycisafecye .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ycisafecye .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #ycisafecye .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ycisafecye .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ycisafecye .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ycisafecye .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ycisafecye .gt_column_spanner_outer:first-child { padding-left: 0; } #ycisafecye .gt_column_spanner_outer:last-child { padding-right: 0; } #ycisafecye .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ycisafecye .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #ycisafecye .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ycisafecye .gt_from_md > :first-child { margin-top: 0; } #ycisafecye .gt_from_md > :last-child { margin-bottom: 0; } #ycisafecye .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ycisafecye .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #ycisafecye .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #ycisafecye .gt_row_group_first td { border-top-width: 2px; } #ycisafecye .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ycisafecye .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #ycisafecye .gt_first_summary_row.thick { border-top-width: 2px; } #ycisafecye .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ycisafecye .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ycisafecye .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ycisafecye .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ycisafecye .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #ycisafecye .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ycisafecye .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #ycisafecye .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ycisafecye .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #ycisafecye .gt_left { text-align: left; } #ycisafecye .gt_center { text-align: center; } #ycisafecye .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ycisafecye .gt_font_normal { font-weight: normal; } #ycisafecye .gt_font_bold { font-weight: bold; } #ycisafecye .gt_font_italic { font-style: italic; } #ycisafecye .gt_super { font-size: 65%; } #ycisafecye .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #ycisafecye .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #ycisafecye .gt_asterisk { font-size: 100%; vertical-align: 0; } #ycisafecye .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #ycisafecye .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #ycisafecye .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } model Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) mod_A 46.06 36,643.55 NA NA NA mod_B 40.03 24,998.24 6.03 11,645.31 0.00 Again though, we could have just used the summary output from the second model. Instances where such a statistical test does not appear to be appropriate within the context of the mgcv package are when terms are able to be penalized to zero; in such a case p-values will be much too low. In addition, when comparing GAMs, sometimes the nesting of models would not be so clear when there are multiple smooths involved, and additional steps may need to be taken to make sure they are nested to use the statistical test. We must make sure that each smooth term in the null model has no more effective degrees of freedom than the same term in the alternative, otherwise it’s possible that the model with more terms can have lower effective degrees of freedom but better fit, rendering the test nonsensical. Wood suggests that if such model comparison is the ultimate goal, an unpenalized approach35 would be best to use in order to have much confidence in the p-values36. Big Data Many times you’ll come across some notably large data for which you’d still like to fit a GAM too. Wood has implemented a lot of speed and memory efficiency into the bam function, which works basically the same as the gam function. Assuming you get the data into memory, even millions of rows will likely pose little issue for mgcv. Where things do start to hurt computationally is in the number of parameters. While mgcv is great just as a mixed model tool to incorporate random effects, as the dimensionality grows, bam’s performance will start to suffer. This would likely not be a big deal for standard implementation of GAM for smooth terms, but when using it for categorical random effects (i.e. bs = 're'), having a lot of groups means a lot of parameters to estimate. I have a demo that provides more details. References "],["other.html", "Other Approaches Other Nonlinear Modeling Approaches Bayesian Estimation Extensions", " Other Approaches This section will discuss some ways to relate GAMs to other forms of nonlinear modeling approaches, some familiar and others perhaps less so. In addition, I will note some extensions to GAMs to consider. Other Nonlinear Modeling Approaches Known Functional Form It should be noted that one can place generalized additive models under a general heading of nonlinear models whose focus may be on transformations of the outcome (as with generalized linear models), the predictor variables (polynomial regression and GAMs), or both (GAMs), in addition to those whose effects are nonlinear in the parameters37 38. A primary difference between GAMs and those models is that we don’t specify the functional form of features beforehand with GAMs. In cases where the functional form may be known, one can use an approach such as nonlinear least squares, and there is inherent functionality with base R, such as the nls function. As is the usual case, such functionality is readily extendable to a great many other analytic situations, e.g. the gnm for generalized nonlinear models or nlme for nonlinear mixed effects models. Response Transformation As noted, it is common practice, perhaps too common, to manually transform the response and go about things with a typical linear model. While there might be specific reasons for doing so, the primary reason many seem to do so is to make the distribution ‘more normal’ so that regular regression methods can be applied, which stems from a misunderstanding of the assumptions of standard regression. As an example, a typical transformation is to take the log, particularly to tame ‘outliers’ or deal with heteroscedasticity. While it was a convenience ‘back in the day’ because we didn’t have software or computing power to deal with a lot of data situations aptly, this is definitely not the case now. In many cases it would be better to, for example, conduct a generalized linear model with a log link, or perhaps assume a different distribution for the response directly (e.g. log- or skew-normal), and many tools allow analysts to do this with ease39. There are still cases where one might focus on response transformation, just not so one can overcome some particular nuisance in trying to fit a linear regression. An example might be in some forms of functional data analysis, where we are concerned with some function of the response that has been measured on many occasions over time. Another example would be in economics, where they like to talk of effects in terms of elasticities. The Black Box A Neural Net Model Venables and Ripley (2002, sec. 11.5) make an interesting delineation of nonlinear models into those that are less flexible but under full user control (fully parametric), and those that are black box techniques that are highly flexible and mostly if not fully automatic: stuff goes in, stuff comes out, but we’re not privy to the specifics40. Two examples of the latter that they provide are projection pursuit and neural net models, though a great many would fall into such a heading. Projection pursuit models are well suited to high dimensional data where dimension reduction is a concern. One can think of an example where one uses a technique such as principal components analysis on the predictor set and then examines smooth functions of \\(M\\) principal components. In the case of neural net models, which have found their stride over the last decade or so under the heading of deep learning, one can imagine a model where the input units (features) are weighted and summed to create hidden layer units, which are then transformed and put through the same process to create outputs (see a simple example above). Neural networks are highly flexible in that there can be any number of inputs, hidden layers, and outputs, along with many, many other complexities besides. And, while such models are very explicit in the black box approach, tools for interpretability have been much more accessible these days. Such models are usually found among a number machine learning techniques, any number of which might be utilized in a number of disciplines. Other more algorithmic/black box approaches include networks/graphical models, and tree-based methods such as random forests and gradient boosting41. As Venables and Ripley note, generalized additive models might be thought of as falling somewhere in between the fully parametric and highly interpretable models of linear regression and more black box techniques, a gray box if you will. Indeed, there are even algorithmic approaches which utilize GAMs as part of their approach, including neural additive models (e.g. Agarwal et al. (2021) and Xu et al. (2022)). Bayesian Estimation We can definitely take a Bayesian approach to our GAMs if desired, in fact, we already have! When we called the summary method, the p-values are based on the Bayesian posterior covariance matrix of parameters. This matrix is also the basis for the standard errors whenever we use the predict method. So our uncertainty estimates are generally Bayesian-ish when using our default approach for span class=“pack”&gt;mgcv42. For a fully Bayesian implementation, the brms package serves as an easy to use starting point in R, and has functionality for using the class=“pack”&gt;mgcv package’s syntax style. The reason is that it just uses mgcv to library(brms) mod_bayes = brm( Overall ~ s(Income, bs = &quot;cr&quot;), data = pisa, thin = 4, cores = 4 ) conditional_effects(mod_bayes) Results are very similar as we would expect. Family: gaussian Links: mu = identity; sigma = identity Formula: Overall ~ s(Income, bs = &quot;cr&quot;) Data: pisa (Number of observations: 54) Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 4; total post-warmup draws = 1000 Smooth Terms: Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS sds(sIncome_1) 5.19 3.28 1.68 13.98 1.00 675 913 Population-Level Effects: Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS Intercept 470.49 4.33 461.76 479.04 1.00 944 981 sIncome_1 7.90 1.35 5.32 10.46 1.00 1025 914 Family Specific Parameters: Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS sigma 31.62 3.40 25.87 39.35 1.00 1035 993 Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS and Tail_ESS are effective sample size measures, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat = 1). Here are 50 posterior draws from the model on the left, with .5, .8, and .95 fitted intervals on the right. Here we compare the uncertainty in the fitted values between the Bayesian and standard mgcv approach43. It looks like the mgcv credible intervals are generally good estimates, but that brms shows a bit more regularization. In any case, it’s easy enough to try a Bayesian approach for your GAM if you want to! Extensions Other GAMs Categorical variables Note that just as generalized additive models are an extension of the generalized linear model, there are generalizations of the basic GAM beyond the settings described. In particular, random effects can be dealt with in this context as they can with linear and generalized linear models, and there is an interesting connection between smooths and random effects in general 44. This allowance for categorical variables, i.e. factors, works also to allow separate smooths for each level of the factor. This amounts to an interaction of the sort we demonstrated with two continuous variables. See the appendix for details. Spatial Modeling Additive models also provide a framework for dealing with spatially correlated data as well. As an example, a Markov Random Field smooth can be implemented for discrete spatial structure, such as countries or states45. For the continuous spatial domain, one can use the 2d smooth as was demonstrated previously, e.g. with latitude and longitude. Again one can consult the appendix for demonstration, and see also the Gaussian process paragraph. Structured Additive Regression Models The combination of random effects, spatial effects, etc. into the additive modeling framework is sometimes given a name of its own- structured additive regression models, or STARs46. It is the penalized regression approach that makes this possible, where we have a design matrix that might include basis functions or an indicator matrix for groups, and an appropriate penalty matrix. With those two components, we can specify the models in almost identical fashion, and combine such effects within a single model. This results in a very powerful regression modeling strategy. Furthermore, the penalized regression described has a connection to Bayesian regression with a normal, zero-mean prior for the coefficients, providing a path toward even more flexible modeling. GAMLSS Generalized additive models for location, scale, and shape (GAMLSS) allow for distributions beyond the exponential family47, and modeling different parameters besides the mean. mgcv also has several options in this regard. Other In addition, there are boosted, ensemble and other machine learning approaches that apply GAMs. It should be noted that boosted models can be seen as GAMs. In short, there’s plenty to continue to explore once one gets the hang of generalized additive models. Reproducing Kernel Hilbert Space Generalized smoothing splines are built on the theory of reproducing kernel Hilbert spaces. I won’t pretend to be able to get into it here, but the idea is that some forms of additive models can be represented in the inner product form used in RKHS approaches48. This connection lends itself to a tie between GAMs and e.g. support vector machines and similar methods. For the interested, I have an example of RKHS regression here. Gaussian Processes We can also approach modeling by using generalizations of the Gaussian distribution. Where the Gaussian distribution is over vectors and defined by a mean vector and covariance matrix, a Gaussian Process is a distribution over functions. A function \\(f\\) is distributed as a Gaussian Process defined by a mean function \\(m\\) and covariance function \\(k\\). They have a close tie to RKHS methods, and generalize commonly used models in spatial modeling. \\[f\\sim \\mathcal{GP}(m,k)\\] In the Bayesian context, we can define a prior distribution over functions and make draws from a posterior predictive distribution of \\(f\\) once we have observed data. The reader is encouraged to consult Rasmussen and Williams (2006) for the necessary detail. The text is free for download, and Rasmussen also provides a nice and brief intro. I also have some R code for demonstration based on his Matlab code, as well as Bayesian examples in Stan in the same document, though Stan offers easier ways to do it these days. Suffice it to say in this context, it turns out that generalized additive models with a tensor product or cubic spline smooth are maximum a posteriori (MAP) estimates of Gaussian processes with specific covariance functions and a zero mean function. In that sense, one might segue nicely to Gaussian processes if familiar with additive models. The mgcv package also allows one to use a spline form of Gaussian process. Furthermore, gaussian process regression is akin to a single layer neural network with an infinite number of hidden nodes. So there is a straightforward thread from GAMs to neural nets as well. Gaussian Process: The left graph shows functions from the prior distribution, the right shows the posterior mean function, 95% confidence interval shaded, as well as specific draws from the posterior predictive mean distribution. References "],["conclusion.html", "Concluding remarks", " Concluding remarks Generalized additive models are a conceptually straightforward tool that allows one to incorporate nonlinear and other relationships into their otherwise linear models. In addition, they allow one to keep within the linear and generalized linear modeling frameworks with which one is already familiar, while providing new avenues of model exploration and improved results. As was demonstrated, it is easy enough with just a modicum of familiarity to pull them off, and as such, it is hoped that this document provided one the means to do so. In closing, I offer the following lifted directly from Shalizi (2016), Advanced Data Analysis from an Elementary Point of View, as I don’t think I could have put it more clearly: With modern computing power, there are very few situations in which it is actually better to do linear regression than to fit an additive model. In fact, there seem to be only two good reasons to prefer linear models. Our data analysis is guided by a credible scientific theory which asserts linear relationships among the variables we measure (not others, for which our observables serve as imperfect proxies). Our data set is so massive that either the extra processing time, or the extra computer memory, needed to fit and store an additive rather than a linear model is prohibitive. Even when the first reason applies, and we have good reasons to believe a linear theory, the truly scientific thing to do would be to check linearity, by fitting a flexible non-linear model and seeing if it looks close to linear. Even when the second reason applies, we would like to know how much bias we’re introducing by using linear predictors, which we could do by randomly selecting a subset of the data which is small enough for us to manage, and fitting an additive model. In the vast majority of cases when users of statistical software fit linear models, neither of these justifications applies: theory doesn’t tell us to expect linearity, and our machines don’t compel us to use it. Linear regression is then employed for no better reason than that users know how to type lm but not gam. You now know better, and can spread the word. Nowadays, GAMs serve as a potentially great starting point for modeling, especially for tabular data. A well-specified GAM should perform very well even compared to boosting or deep learning methods, and so at the very least, serves as a good baseline with enhanced interpretability and easier uncertainty metrics. For a lot of data situations, GAMs may be all you need. Best of luck with your data! References "],["technical.html", "Technical details GAM A detailed example The number of knots and where to put them Interpreting output for smooth terms", " Technical details This section is for some of the more technically inclined, though you’ll find more context and detail in and S. N. Wood (2006) and S. N. Wood (2017), from which a good chunk of this section is taken more or less directly from. GAM As we noted before, a GAM is a GLM whose linear predictor includes a sum of smooth functions of covariates. With link function \\(g(.)\\), model matrix \\(X\\) of \\(n\\) rows and \\(p\\) features (plus a column for the intercept), a vector of \\(p\\) coefficients \\(\\beta\\), we can write a GLM as follows: \\[\\mathrm{GLM:}\\quad g(\\mu) = X\\beta\\] For the GAM, it could look something like: \\[\\mathrm{GAM:}\\quad g(\\mu) = X\\beta + f(x_1) + f(x_2) + f(x_3, x_4) + \\ldots\\] or in a manner similar to mixed models: \\[\\mathrm{GAM:}\\quad g(\\mu) = X\\beta + Z\\gamma\\] Where \\(Z\\) represents the basis functions of some subset of \\(X\\) or other features. So, we can have any number of smooth terms, possibly of different bases, and even combinations of them. Finally, we can depict the structured additive regression, or STAR, model as a GAM + categorical random effects (\\(\\Upsilon\\)) + spatial effects (\\(\\Xi\\)) + other fun stuff (\\(?\\)). \\[\\mathrm{STAR:}\\quad g(\\mu) = X\\beta + Z\\gamma + \\Upsilon\\varpi + \\Xi\\varrho + \\ldots \\mathbf{?}\\vartheta \\] Penalized regression Consider a standard GLM that we usually estimate with maximum likelihood, \\(l(\\beta)\\), where \\(\\beta\\) are the associated regression coefficients. We can write the penalized likelihood as follows: \\[l_p(\\beta)= l(\\beta) - \\color{#b2001d}{\\lambda B&#39;SB}\\] Where \\(S\\) is a penalty matrix of known coefficients49. If you prefer least squares as the loss function, we can put it as: \\[\\mathcal{Loss} = \\sum (y-X\\beta)^2 + \\color{#b2001d}{\\lambda B&#39;SB}\\] So, if we’re maximizing the likelihood will make it lower than it otherwise would have been, and vice versa in terms of a loss function. What it means for a GAM is that we’ll add a penalty for the coefficients associated with the basis functions50. The practical side is that it will help to keep us from overfitting the data, where our smooth function might get too wiggly. As \\(\\lambda \\rightarrow \\infty\\), the result is a linear fit because any wiggliness will add too much to the loss function. As \\(\\lambda \\rightarrow 0\\), we have the opposite effect, where any wiggliness is incorporated into the model. In mgcv, by default the estimated parameters are chosen via a generalized cross validation, or GCV, approach, and that statistic is reported in the summary. It modifies the loss function depicted above to approximate leave-one-out cross-validation selection. Effective degrees of freedom again If we define a matrix \\(F\\) that maps the unpenalized estimates of \\(\\beta\\) to the penalized estimates such that \\[F = (X^T X + S)^{-1} X^T X\\] and note \\[\\tilde{\\beta} = (X^T X)^{-1} X^T y\\] \\[\\hat{\\beta} = F\\tilde{\\beta}\\] the diagonal elements of \\(F\\) are the effective degrees of freedom for each feature. A detailed example The following will demonstrate a polynomial spline by hand51. The example, and in particular the visual display, is based on a depiction in Fahrmeir et al. (2013) (figure 8.6) 52. The approach is defined as follows, with \\(\\kappa\\) knots on the interval \\([a,b]\\) as \\(a=\\kappa_1 &lt; ... &lt; \\kappa_m =b\\): \\[y_i = \\gamma_1 + \\gamma_2x_i + ... + \\gamma_{l+1}(x_i)_+^l + \\gamma_{l+2}(x_i - \\kappa_2)_+^l ... + \\gamma_{l+m-1}(x_i - \\kappa_{m-1})_+^l + e_i\\] \\[(x - \\kappa_j)^l_+= \\begin{cases} (x-\\kappa_j)^l &amp; x \\geq \\kappa_j \\\\ 0 &amp; \\textrm{otherwise} \\end{cases}\\] So we subtract the current knot being considered from \\(x\\) for values of \\(x\\) greater than or equal to the knot, otherwise, it’s 0. It might look complicated, but note that there is nothing particularly special about the model itself. It is just a standard linear regression model when everything is said and done. More generally we can write a GAM as follows: \\[y = f(x) + e = \\sum_{j=1}^{d}B_j(x)\\gamma_j + e\\] With the spline above this becomes: \\[B_1(x)=1, B_2(x)=x, ..., B_{l+1}(x)=x^l, B_{l+2}(x)=(x-\\kappa_2)_+^l...B_{d}(x)=(x-\\kappa_{m-1})_+^l\\] Let’s see it in action. Here our polynomial spline will be done with degree \\(l\\) equal to 1, which means that we are just fitting a linear regression between knots. The following uses the data we employed for demonstration before. # data same as earlier examples set.seed(123) x = runif(500) mu = sin(2 * (4 * x - 2)) + 2 * exp(-(16 ^ 2) * ((x - .5) ^ 2)) y = rnorm(500, mu, .3) knots = seq(0, 1, by = .1) d = tibble(x, y) %&gt;% mutate( xcut = cut(x, knots, right = F), xcut = factor(xcut, levels = c(&#39;Int&#39;, levels(xcut))) ) # knots = seq(0, 1, by = .1) knots = knots[-length(knots)] # don&#39;t need the last value l = 1 bs = sapply( 1:length(knots), function(k) ifelse(x &gt;= knots[k], (x - knots[k]) ^ l, 0) ) # head(bs) @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #cnrjlpczle .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #cnrjlpczle .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #cnrjlpczle .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #cnrjlpczle .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cnrjlpczle .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #cnrjlpczle .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #cnrjlpczle .gt_column_spanner_outer:first-child { padding-left: 0; } #cnrjlpczle .gt_column_spanner_outer:last-child { padding-right: 0; } #cnrjlpczle .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #cnrjlpczle .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #cnrjlpczle .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #cnrjlpczle .gt_from_md > :first-child { margin-top: 0; } #cnrjlpczle .gt_from_md > :last-child { margin-bottom: 0; } #cnrjlpczle .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #cnrjlpczle .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #cnrjlpczle .gt_row_group_first td { border-top-width: 2px; } #cnrjlpczle .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #cnrjlpczle .gt_first_summary_row.thick { border-top-width: 2px; } #cnrjlpczle .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #cnrjlpczle .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #cnrjlpczle .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #cnrjlpczle .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #cnrjlpczle .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #cnrjlpczle .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #cnrjlpczle .gt_left { text-align: left; } #cnrjlpczle .gt_center { text-align: center; } #cnrjlpczle .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #cnrjlpczle .gt_font_normal { font-weight: normal; } #cnrjlpczle .gt_font_bold { font-weight: bold; } #cnrjlpczle .gt_font_italic { font-style: italic; } #cnrjlpczle .gt_super { font-size: 65%; } #cnrjlpczle .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #cnrjlpczle .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #cnrjlpczle .gt_asterisk { font-size: 100%; vertical-align: 0; } #cnrjlpczle .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #cnrjlpczle .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #cnrjlpczle .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 0.288 0.188 0.088 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.788 0.688 0.588 0.488 0.388 0.288 0.188 0.088 0.000 0.000 0.409 0.309 0.209 0.109 0.009 0.000 0.000 0.000 0.000 0.000 0.883 0.783 0.683 0.583 0.483 0.383 0.283 0.183 0.083 0.000 0.940 0.840 0.740 0.640 0.540 0.440 0.340 0.240 0.140 0.040 0.046 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 If we plot this against our target variable \\(y\\), it doesn’t look like much, but we can maybe start to see the partitioning of the effect by knots. If we multiply each basis by its corresponding regression coefficient we can start to interpret the result. lmMod = lm(y ~ . - 1, data = bs) # just a regression! bscoefs = coef(lmMod) bsScaled = sweep(bs, 2, bscoefs,`*`) colnames(bsScaled) = c(&#39;int&#39;, paste0(&#39;X&#39;, 1:10)) ## bscoefs @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #mhqesfbqwq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mhqesfbqwq .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mhqesfbqwq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mhqesfbqwq .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mhqesfbqwq .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mhqesfbqwq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mhqesfbqwq .gt_column_spanner_outer:first-child { padding-left: 0; } #mhqesfbqwq .gt_column_spanner_outer:last-child { padding-right: 0; } #mhqesfbqwq .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mhqesfbqwq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #mhqesfbqwq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mhqesfbqwq .gt_from_md > :first-child { margin-top: 0; } #mhqesfbqwq .gt_from_md > :last-child { margin-bottom: 0; } #mhqesfbqwq .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mhqesfbqwq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mhqesfbqwq .gt_row_group_first td { border-top-width: 2px; } #mhqesfbqwq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mhqesfbqwq .gt_first_summary_row.thick { border-top-width: 2px; } #mhqesfbqwq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mhqesfbqwq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mhqesfbqwq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mhqesfbqwq .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #mhqesfbqwq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mhqesfbqwq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mhqesfbqwq .gt_left { text-align: left; } #mhqesfbqwq .gt_center { text-align: center; } #mhqesfbqwq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mhqesfbqwq .gt_font_normal { font-weight: normal; } #mhqesfbqwq .gt_font_bold { font-weight: bold; } #mhqesfbqwq .gt_font_italic { font-style: italic; } #mhqesfbqwq .gt_super { font-size: 65%; } #mhqesfbqwq .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #mhqesfbqwq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #mhqesfbqwq .gt_asterisk { font-size: 100%; vertical-align: 0; } #mhqesfbqwq .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #mhqesfbqwq .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #mhqesfbqwq .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } int X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 0.783 &minus;6.637 &minus;1.388 3.839 7.366 25.769 &minus;41.462 15.167 &minus;7.144 &minus;1.738 &minus;3.394 In the plot above, the initial dot represents the global constant (\\(\\gamma_1\\), i.e. our intercept). We have a decreasing function starting from that point onward (line). Between .1 and .2 (line), the coefficient is negative again, furthering the already decreasing slope (i.e. steeper downward). The fourth coefficient is positive, which means that between .2 and .3 our decreasing trend is lessening (line). So our coefficients \\(j\\) tell us the change in slope for the data from the previous section of data defined by the knots. The lengths of the lines reflect the size of the coefficient, i.e. how dramatic the change is. If this gets you to thinking about interactions in more common model settings, you’re on the right track (e.g. adding a quadratic term is just letting x have an interaction with itself; same thing is going on here). Finally, if we plot the sum of the basis functions, which is the same as taking our fitted values from a regression on the basis expansion of X, we get the following fit to the data. And we can see the trend our previous plot suggested. One of the more common approaches with GAMs uses a cubic spline fit. So we’ll change our polynomial degree from 1 to 3 (i.e. l = 3). Now we’re getting somewhere. Let’s compare it to the gam function from the mgcv package. We won’t usually specify the knots directly, and even as we have set things up similar to the mgcv approach, the gam function is still doing some things our by-hand approach is not (penalized regression). We still get pretty close agreement however. We can see that we’re on the right track by using the constructor function within mgcv and a custom function for truncated power series like what we’re using above. See the example in the help file for smooth.construct for the underlying truncated power series function. I only show a few of the columns, but our by-hand construction and that used by gam are identical. xs = scale(x, scale = F) bs = sapply(1:length(knots), function(k) ifelse(x &gt;= knots[k], (x - knots[k]) ^ l, 0)) ## sm = smoothCon(s(x, bs = &#39;tr&#39;, k = 14), data = d, knots = list(x = knots))[[1]] # head(sm$X[, 1:6]) modelMatrix = cbind(1, xs, xs^2, xs^3, bs) all.equal(sm$X, modelMatrix) [1] TRUE @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #hsrzsenlxa .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #hsrzsenlxa .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #hsrzsenlxa .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #hsrzsenlxa .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #hsrzsenlxa .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #hsrzsenlxa .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #hsrzsenlxa .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #hsrzsenlxa .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #hsrzsenlxa .gt_column_spanner_outer:first-child { padding-left: 0; } #hsrzsenlxa .gt_column_spanner_outer:last-child { padding-right: 0; } #hsrzsenlxa .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #hsrzsenlxa .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #hsrzsenlxa .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #hsrzsenlxa .gt_from_md > :first-child { margin-top: 0; } #hsrzsenlxa .gt_from_md > :last-child { margin-bottom: 0; } #hsrzsenlxa .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #hsrzsenlxa .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #hsrzsenlxa .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #hsrzsenlxa .gt_row_group_first td { border-top-width: 2px; } #hsrzsenlxa .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #hsrzsenlxa .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #hsrzsenlxa .gt_first_summary_row.thick { border-top-width: 2px; } #hsrzsenlxa .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #hsrzsenlxa .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #hsrzsenlxa .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #hsrzsenlxa .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #hsrzsenlxa .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #hsrzsenlxa .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #hsrzsenlxa .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #hsrzsenlxa .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #hsrzsenlxa .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #hsrzsenlxa .gt_left { text-align: left; } #hsrzsenlxa .gt_center { text-align: center; } #hsrzsenlxa .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #hsrzsenlxa .gt_font_normal { font-weight: normal; } #hsrzsenlxa .gt_font_bold { font-weight: bold; } #hsrzsenlxa .gt_font_italic { font-style: italic; } #hsrzsenlxa .gt_super { font-size: 65%; } #hsrzsenlxa .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #hsrzsenlxa .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #hsrzsenlxa .gt_asterisk { font-size: 100%; vertical-align: 0; } #hsrzsenlxa .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #hsrzsenlxa .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #hsrzsenlxa .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } V1 V2 V3 V4 V5 V6 1.000 &minus;0.208 0.043 &minus;0.009 0.024 0.007 1.000 0.293 0.086 0.025 0.490 0.326 1.000 &minus;0.086 0.007 &minus;0.001 0.068 0.029 1.000 0.388 0.150 0.058 0.689 0.480 1.000 0.445 0.198 0.088 0.832 0.594 1.000 &minus;0.450 0.202 &minus;0.091 0.000 0.000 Preview of other bases As an example of other types of smooth terms we might use, here are the basis functions for b-splines. They work notably differently, e.g. over intervals of \\(l+2\\) knots. An easy way to create your own matrix and subsequent plot of this sort would be to use the basis function in the gratia package, which is basically a cleaner version of the mgcv approach. The number of knots and where to put them A natural question may arise as to how many knots to use. More knots potentially means more ‘wiggliness’, as demonstrated here (feel free to click on the different knot values). Note that these are number of knots, not powers in a polynomial regression as shown in the main section of this document. However, we don’t really have to worry about this except in the conceptual sense, i.e. being able to control the wiggliness. The odds of you knowing beforehand the number of knots and where to put them is somewhere between slim and none, so it’s good that we can control this via a single parameter and via a more automatic process. Interpreting output for smooth terms Effective degrees of freedom In interpreting the output from mgcv, we’ll start with the effective degrees of freedom, or edf. In typical OLS regression, the model degrees of freedom is equivalent to the number of predictors/terms in the model. This is not so straightforward with a GAM due to the smoothing process and the penalized regression estimation procedure. In our previous example in the application section, there are actually 9 terms associated with the smooth term, but their corresponding parameters are each penalized to some extent, and so the effective degrees of freedom does not equal 9. For hypothesis testing, an alternate edf is actually used, which is the other one provided there in the summary result (Ref.df). For more on this see ?summary.gam and ?anova.gam. At this point you might be thinking these p-values are a bit fuzzy, and you’d be right. As is the case with mixed models, machine learning approaches, etc., p-values are not straightforward. The gist is that in the GAM setting they aren’t to be used for harsh cutoffs, say, at an arbitrary .05 level, but then standard p-values shouldn’t be used that way either. If they are pretty low you can feel comfortable claiming statistical significance, but if you want a tight p-value you’ll need to go back to using a non-penalized approach like standard GLM. The edf would equal 1 if the model penalized the smooth term to a simple linear relationship53, and so the effective degrees of freedom falls somewhere between 1 and k-1 (or k), where k is chosen based on the basis. You can think of it as akin to the number of knots. There is functionality to choose the k value, but note the following from Wood in the help file for ?choose.k: So, exact choice of k is not generally critical: it should be chosen to be large enough that you are reasonably sure of having enough degrees of freedom to represent the underlying ‘truth’ reasonably well, but small enough to maintain reasonable computational efficiency. Clearly ‘large’ and ‘small’ are dependent on the particular problem being addressed. And the following: One scenario that can cause confusion is this: a model is fitted with k=10 for a smooth term, and the EDF for the term is estimated as 7.6, some way below the maximum of 9. The model is then refitted with k=20 and the EDF increases to 8.7 - what is happening - how come the EDF was not 8.7 the first time around? The explanation is that the function space with k=20 contains a larger subspace of functions with EDF 8.7 than did the function space with k=10: one of the functions in this larger subspace fits the data a little better than did any function in the smaller subspace. These subtleties seldom have much impact on the statistical conclusions to be drawn from a model fit, however. If you want a more statistically oriented approach, see ?gam.check. Deviance explained R-sq.(adj) = 0.904 Deviance explained = 92.1% GCV = 0.010074 Scale est. = 0.0081687 n = 58 For the standard Gaussian setting, we can use our R2. Also provided is ‘deviance explained’, which in this setting is identical to the unadjusted R2, but for non-Gaussian families would be preferred. As noted above, the GCV, or generalized cross validation score, can be taken as an estimate of the mean square prediction error based on a leave-one-out cross validation estimation process. Steps can be taken to choose model parameters specifically based on this (it’s actually the default, as opposed to, e.g. maximum likelihood). Visual depiction The following reproduces the plots produced by mgcv. I’ll even use base R plotting to ‘keep it real’. First we’ll start with the basic GAM plot using our mod_gam2 from the application section. First we get the term for year, i.e. the linear combination of the basis functions for year. The mgcv package provides this for you via the predict function with type='terms'. For non-smooth components, this is just the original covariate times its corresponding coefficient. Next we need the partial residuals, which are just the basic residuals plus the term of interest added. With the original predictor variable, we’re ready to proceed. income_term = predict(mod_gam2, type = &#39;terms&#39;)[, &#39;s(Income)&#39;] res_partial = residuals(mod_gam2) + income_term Income = mod_gam2$model$Income par(mfrow = c(1, 2)) plot( x = Income, y = res_partial, ylim = c(-200, 100), col = &#39;black&#39;, ylab = &#39;s(income, 7.59)&#39;, pch = 19, main = &#39;ours&#39; ) lines(Income[order(Income)], income_term[order(Income)]) plot( mod_gam2, select = 1, se = F, residuals = T, pch = 19, rug = F, ylim = c(-200, 100), main = &#39;mgcv&#39; ) Now for a comparison to ggeffects, which is an easy tool to use to get predictions on the response scale. It uses the underlying predict function also, but gets a standard prediction while holding the other variables at key values (which you can manipulate). By default, these key values are at the median for numeric variables, and most common category for categorical variables. Note that we could add more fitted values to make the line smoother, but for our purposes getting the concept is the goal. pred_data = pisa %&gt;% select(Edu, Health) %&gt;% summarise_all(median, na.rm = TRUE) %&gt;% tibble(Income = mod_gam2$model$Income) plot_data = tibble( Income = pred_data$Income, preds = predict(mod_gam2, newdata = pred_data), p_resid = mod_gam2$residuals + preds ) p1 = plot_data %&gt;% ggplot(aes(x = Income, y = preds)) + geom_line(alpha = .5) p2 = plot( ggeffects::ggpredict(mod_gam2, terms = &#39;Income&#39;), ci = FALSE, use.theme = FALSE, show.title = FALSE ) Examining first derivatives It may be the case that we’d like to investigate the slopes of the smooth terms at various points to better understand how change is taking place. In standard linear model, the slope is constant, so the regression coefficient for a particular feature tells us all we need to know. For additive models or others with nonlinear effects, the slope changes over the values of the feature of interest. We can easily extract this information using the gratia package54, specifically with the fderiv function. This allows one to get the estimated slope at various points, either by specifying them with the newdata argument or specifying the number of values desired along the range of the the model covariate, as below. library(gratia) fd_inc = derivatives(mod_gam1, n = 500) While we we can start to make sense of things by looking at the standard effect plot, we can get more precise with this approach if desired. Here we see that the initial flattening a little after .6 on Income, and both the peak positive slope and sharpest negative slope (blue dots). Depending on the modeling context, one may see patterns of theoretical importance or what theory would predict. In other cases, it just gives you more to talk about. References "],["appendix.html", "Appendix R packages A comparison to mixed models Time and Space", " Appendix R packages The following is a non-exhaustive list of R packages which contain GAM functionality. Each is linked to the CRAN page for the package. Note also that several build upon the mgcv package used for this document. I haven’t really looked much lately, as between mgcv and brms there is little you can’t do. I can vouch that gamlss and VGAM are decent too, but I’ve not used either in a long time. brms Allows for Bayesian GAMs via the Stan modeling language (very new implementation). CausalGAM This package implements various estimators for average treatment effects. gam Functions for fitting and working with generalized additive models. gamboostLSS: Boosting models for fitting generalized additive models for location, shape and scale (gamLSS models). GAMens: This package implements the GAMbag, GAMrsm and GAMens ensemble classifiers for binary classification. gamlss: Generalized additive models for location, shape, and scale. gamm4: Fit generalized additive mixed models via a version of mgcv’s gamm function. gss: A comprehensive package for structural multivariate function estimation using smoothing splines. mgcv: Routines for GAMs and other generalized ridge regression with multiple smoothing parameter selection by GCV, REML or UBRE/AIC. Also GAMMs. VGAM: Vector generalized linear and additive models, and associated models. A comparison to mixed models We noted previously that there were ties between generalized additive and mixed models. Aside from the identical matrix representation noted in the technical section, one of the key ideas is that the penalty parameter for the smooth coefficients reflects the ratio of the residual variance to the variance components for the random effects (see Fahrmeier et al., 2013, p. 483). Conversely, we can recover the variance components by dividing the scale by the penalty parameter. To demonstrate this, we can set things up by running what will amount to equivalent models in both mgcv and lme4 using the sleepstudy data set that comes from the latter55. I’ll run a model with random intercepts and slopes, and for this comparison the two random effects will not be correlated. We will use the standard smoothing approach in mgcv, just with the basis specification for random effects - bs='re'. In addition, we’ll use restricted maximum likelihood as is the typical default in mixed models. library(lme4) mixed_model = lmer(Reaction ~ Days + (1|Subject) + (0 + Days|Subject), data = sleepstudy) ga_model = gam( Reaction ~ Days + s(Subject, bs = &#39;re&#39;) + s(Days, Subject, bs = &#39;re&#39;), data = sleepstudy, method = &#39;REML&#39; ) In the following we can see they agree on the fixed/parametric effects, but our output for the GAM is in the usual, albeit, uninterpretable form. So, we’ll have to translate the smooth terms from the GAM to variance components as in the mixed model. summary(mixed_model) Linear mixed model fit by REML [&#39;lmerMod&#39;] Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject) Data: sleepstudy REML criterion at convergence: 1743.7 Scaled residuals: Min 1Q Median 3Q Max -3.9626 -0.4625 0.0204 0.4653 5.1860 Random effects: Groups Name Variance Std.Dev. Subject (Intercept) 627.57 25.051 Subject.1 Days 35.86 5.988 Residual 653.58 25.565 Number of obs: 180, groups: Subject, 18 Fixed effects: Estimate Std. Error t value (Intercept) 251.405 6.885 36.513 Days 10.467 1.560 6.712 Correlation of Fixed Effects: (Intr) Days -0.184 summary(ga_model) Family: gaussian Link function: identity Formula: Reaction ~ Days + s(Subject, bs = &quot;re&quot;) + s(Days, Subject, bs = &quot;re&quot;) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 251.405 6.885 36.513 &lt; 2e-16 *** Days 10.467 1.560 6.712 3.67e-10 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value s(Subject) 12.94 17 89.29 1.09e-06 *** s(Days,Subject) 14.41 17 104.56 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.794 Deviance explained = 82.7% -REML = 871.83 Scale est. = 653.58 n = 180 Conceptually, we can demonstrate the relationship with the following code that divides the scale by the penalty parameters, one for each of the smooth terms. However, there has been some rescaling behind the scenes regarding the Days effect, so we have to rescale it to get what we need. rescaled_results = c( ga_model$reml.scale / ga_model$sp[1], ga_model$reml.scale / (ga_model$sp[2] / ga_model$smooth[[2]]$S.scale), NA ) lmer_vcov = VarCorr(mixed_model) %&gt;% data.frame() gam_vcov = data.frame(var = rescaled_results, gam.vcomp(ga_model)) My personal package mixedup does this for you, and otherwise makes comparing mixed models from different sources easier. mixedup::extract_variance_components(mixed_model) mixedup::extract_variance_components(ga_model) @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #prtgejdhqe .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #prtgejdhqe .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #prtgejdhqe .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #prtgejdhqe .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #prtgejdhqe .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #prtgejdhqe .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #prtgejdhqe .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #prtgejdhqe .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #prtgejdhqe .gt_column_spanner_outer:first-child { padding-left: 0; } #prtgejdhqe .gt_column_spanner_outer:last-child { padding-right: 0; } #prtgejdhqe .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #prtgejdhqe .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #prtgejdhqe .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #prtgejdhqe .gt_from_md > :first-child { margin-top: 0; } #prtgejdhqe .gt_from_md > :last-child { margin-bottom: 0; } #prtgejdhqe .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #prtgejdhqe .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #prtgejdhqe .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #prtgejdhqe .gt_row_group_first td { border-top-width: 2px; } #prtgejdhqe .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #prtgejdhqe .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #prtgejdhqe .gt_first_summary_row.thick { border-top-width: 2px; } #prtgejdhqe .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #prtgejdhqe .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #prtgejdhqe .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #prtgejdhqe .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #prtgejdhqe .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #prtgejdhqe .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #prtgejdhqe .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #prtgejdhqe .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #prtgejdhqe .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #prtgejdhqe .gt_left { text-align: left; } #prtgejdhqe .gt_center { text-align: center; } #prtgejdhqe .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #prtgejdhqe .gt_font_normal { font-weight: normal; } #prtgejdhqe .gt_font_bold { font-weight: bold; } #prtgejdhqe .gt_font_italic { font-style: italic; } #prtgejdhqe .gt_super { font-size: 65%; } #prtgejdhqe .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #prtgejdhqe .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #prtgejdhqe .gt_asterisk { font-size: 100%; vertical-align: 0; } #prtgejdhqe .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #prtgejdhqe .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #prtgejdhqe .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } model group effect variance sd sd_2.5 sd_97.5 var_prop mixed Subject Intercept 627.57 25.05 15.26 37.79 0.48 mixed Subject.1 Days 35.86 5.99 3.96 8.77 0.03 mixed Residual 653.58 25.57 22.88 28.79 0.50 gam Subject Intercept 627.57 25.05 16.09 39.02 0.48 gam Subject Days 35.86 5.99 4.03 8.91 0.03 gam Residual 653.58 25.57 22.79 28.68 0.50 Think about it this way. Essentially what is happening behind the scenes is that effect interactions with the grouping variable are added to the model matrix (e.g. ~ ... + Days:Subject - 1)56. The coefficients pertaining to the interaction terms are then penalized in the typical GAM estimation process. A smaller estimated penalty parameter suggests more variability in the random effects. A larger penalty means more shrinkage of the random intercepts and slopes toward the population level (fixed) effects. Going further, we can think of smooth terms as adding random effects to the linear component57. A large enough penalty and the result is simply the linear part of the model. In this example here, that would be akin to relatively little random effect variance. Time and Space One of the things to know about GAMs is just how flexible they are. Along with all that we have mentioned, they can also be applied to situations where one is interested in temporal trends or the effects of spatial aspects of the data. The penalized regression approach used by GAMs can easily extend such situations, and the mgcv package in particular has a lot of options here. Time A natural setting for GAMs is where there are observations over time. Perhaps we want to examine the trend over time. The SLiM would posit a linear trend, but we often would doubt that is the case. How would we do this with a GAM? We can incorporate a feature representing the time component and add it as a smooth term. There will be some additional issues though as we will see. Here I use the data and example at Gavin Simpon’s nifty blog, though with my own edits, updated data, and different model58. The data regards global temperature anomalies. ## Global temperatures # Original found at &quot;https://crudata.uea.ac.uk/cru/data/temperature/&quot; load(url(&#39;https://github.com/m-clark/generalized-additive-models/raw/master/data/global_temperatures.RData&#39;)) Fitting a straight line to this would be disastrous, so let’s do a GAM. hot_gam = gam(Annual ~ s(Year), data = gtemp) summary(hot_gam) Family: gaussian Link function: identity Formula: Annual ~ s(Year) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.076564 0.007551 -10.14 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value s(Year) 7.923 8.696 182.2 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.903 Deviance explained = 90.7% GCV = 0.010342 Scale est. = 0.0098059 n = 172 We can see that the trend is generally increasing, and has been more or less since the beginning of the 20th century. We have a remaining issue though. In general, a time series is autocorrelated, i.e. correlated with itself over time. We can see this in the following plot. acf(gtemp$Annual) What the plot shows is the correlation of the values with themselves at different lags, or time spacings. Lag 0 is it’s correlation with itself, so the value is 1.0. It’s correlation with itself at the previous time point, i.e. lag = 1, is 0.92, it’s correlation with itself at two time points ago is slightly less, 0.86, and the decreasing trend continues slowly. The dotted lines indicate a 95% confidence interval around zero, meaning that the autocorrelation is still significant 25 years apart. With our model, the issue remains in that there is still autocorrelation among the residuals, at least at lag 1. The practical implications of autocorrelated residuals is that this positive correlation would result in variance estimates that are too low. However, we can take this into account with a slight tweaking of our model to incorporate such autocorrelation. For our purposes, we’ll switch to the gamm function. It adds additional functionality for generalized additive mixed models, though we can just use it to incorporate autocorrelation of the residuals. In running this, two sets of output are provided, one in our familiar gam model object, and the other as a lme object from the nlme package. hot_gam_ar = gamm(Annual ~ s(Year), data = gtemp, correlation = corAR1(form = ~ Year)) summary(hot_gam_ar$gam) Family: gaussian Link function: identity Formula: Annual ~ s(Year) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.07696 0.01130 -6.812 1.73e-10 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value s(Year) 6.879 6.879 104.1 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.901 Scale est. = 0.010297 n = 172 summary(hot_gam_ar$lme) Linear mixed-effects model fit by maximum likelihood Data: strip.offset(mf) AIC BIC logLik -289.0641 -273.3266 149.5321 Random effects: Formula: ~Xr - 1 | g Structure: pdIdnot Xr1 Xr2 Xr3 Xr4 Xr5 Xr6 Xr7 Xr8 Residual StdDev: 1.252053 1.252053 1.252053 1.252053 1.252053 1.252053 1.252053 1.252053 0.1014737 Correlation Structure: AR(1) Formula: ~Year | g Parameter estimate(s): Phi 0.3614622 Fixed effects: y ~ X - 1 Value Std.Error DF t-value p-value X(Intercept) -0.0769567 0.0113296 170 -6.792539 0.0000 Xs(Year)Fx1 0.4282956 0.1692888 170 2.529970 0.0123 Correlation: X(Int) Xs(Year)Fx1 0 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -2.21288171 -0.73869325 0.04665656 0.70416540 3.25638634 Number of Observations: 172 Number of Groups: 1 In the gam output, we see some slight differences from the original model, but not much (and we wouldn’t expect it). From the lme output we can see the estimated autocorrelation value denoted as Phi59. Let’s see what it does for the uncertainty in our model estimates. We can in fact see that we were a bit optimistic in the previous fit (darker band). Our new fit expreses more uncertainty at every point60. So, in using a GAM for time-series data, we have similar issues that we’d have with standard regression settings, and we can deal with them in much the same way to get a better sense of the uncertainty in our estimates. Space Consider a data set with latitude and longitude coordinates to go along with other features used to model some target variable. A spatial regression analysis uses an approach to account for spatial covariance among the observation points. A common technique used is a special case of Gaussian process which, as we noted previously, certain types of GAMs can be seen as such also. In addition, some types of spatial models can be seen similar to random effects models, much like GAMs. Such connections mean that we can add spatial models to the sorts of models covered by GAMs too. When dealing with space, we may have spatial locations of a continuous sort, such as with latitude and longitude, or in a discrete sense, such as regions. In what follows we’ll examine both cases. Continuous Spatial Setting Our example61 will use census data from New Zealand and focus on median income. It uses the nzcensus package62 which includes median income, latitude, longitude and several dozen other variables. The latitude and longitude are actually centroids of the area unit, so this technically could also be used as a discrete example based on the unit. Let’s take an initial peek. You can hover over the points to get the location and income information. library(nzcensus) nz_census = AreaUnits2013 %&gt;% filter(WGS84Longitude &gt; 0 &amp; !is.na(MedianIncome2013)) %&gt;% rename(lon = WGS84Longitude, lat = WGS84Latitude, Income = MedianIncome2013) %&gt;% drop_na() So we can go ahead and run a model predicting median income solely by geography. We’ll use a Gaussian process basis, and allowing latitude and longitude to interact (bumping up the default wiggliness possible to allow for a little more nuance). What the GAM will allow us to do is smooth our predictions beyond the points we have in the data to get a more complete picture of income distribution across the whole area6364. nz_gam = gam(Income ~ s(lon, lat, bs = &#39;gp&#39;, k = 100, m = 2), data = nz_census) summary(nz_gam) Family: gaussian Link function: identity Formula: Income ~ s(lon, lat, bs = &quot;gp&quot;, k = 100, m = 2) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 29497.8 148.1 199.2 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df F p-value s(lon,lat) 76.38 90.1 7.445 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.27 Deviance explained = 30.1% GCV = 4.0878e+07 Scale est. = 3.9105e+07 n = 1784 Using the Gaussian process smooth produces a result that is akin to a traditional spatial modeling technique called kriging. There are many other features to play with, as well as other bases that would be applicable, so you should feel free to play around with models that include those. Alternatively, as we did with the time series, we could instead deal with spatial autocorrelation by specifying a model for the residual structure. First, we can simply test for spatial autocorrelation in the income variable via the well-worn Moran’s I statistic. Given some weight matrix that specifies the neighborhood structure, such that larger values mean points are closer to one another, we can derive an estimate. The following demonstrates this via the ape package65. inv_dist = with(nz_census, 1/dist(cbind(lat, lon), diag = TRUE, upper = TRUE)) inv_dist = as.matrix(inv_dist) ## ape::Moran.I(nz_census$Income, weight = inv_dist, scaled = TRUE) @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #gvlmjazong .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #gvlmjazong .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gvlmjazong .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #gvlmjazong .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #gvlmjazong .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gvlmjazong .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gvlmjazong .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #gvlmjazong .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #gvlmjazong .gt_column_spanner_outer:first-child { padding-left: 0; } #gvlmjazong .gt_column_spanner_outer:last-child { padding-right: 0; } #gvlmjazong .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #gvlmjazong .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #gvlmjazong .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #gvlmjazong .gt_from_md > :first-child { margin-top: 0; } #gvlmjazong .gt_from_md > :last-child { margin-bottom: 0; } #gvlmjazong .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #gvlmjazong .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #gvlmjazong .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #gvlmjazong .gt_row_group_first td { border-top-width: 2px; } #gvlmjazong .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gvlmjazong .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #gvlmjazong .gt_first_summary_row.thick { border-top-width: 2px; } #gvlmjazong .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gvlmjazong .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gvlmjazong .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #gvlmjazong .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #gvlmjazong .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #gvlmjazong .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gvlmjazong .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #gvlmjazong .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gvlmjazong .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gvlmjazong .gt_left { text-align: left; } #gvlmjazong .gt_center { text-align: center; } #gvlmjazong .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #gvlmjazong .gt_font_normal { font-weight: normal; } #gvlmjazong .gt_font_bold { font-weight: bold; } #gvlmjazong .gt_font_italic { font-style: italic; } #gvlmjazong .gt_super { font-size: 65%; } #gvlmjazong .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #gvlmjazong .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #gvlmjazong .gt_asterisk { font-size: 100%; vertical-align: 0; } #gvlmjazong .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #gvlmjazong .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #gvlmjazong .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } observed expected sd p.value 0.14 0.00 0.00 0.00 While statistically significant, there actually isn’t too much going on, though it may be enough to warrant dealing with in some fashion. As with the time series, we’ll have to use the functionality with gamm, where the underlying nlme package provides functions for spatial correlation structures. The following shows how this might be done. If you run this be prepared to wait for a few minutes. gamm_spat = gamm( Income ~ s(x) + s(y) + z, # choose your own features here data = nz_census, correlation = corSpatial(form = ~ lon + lat, type = &#39;gaussian&#39;) ) plot(gamm_spat) So whether you choose to deal with the spatial autocorrelation explicitly by using something like coordinates as features in the model itself, or via the residual correlation structure, or perhaps both, is up to you66. Discrete What about the discrete case, where the spatial random effect is based on geographical regions? This involves a penalty that is based on the adjacency matrix of the regions, where if there are \\(g\\) regions, the adjacency matrix is a \\(g \\times g\\) indicator matrix where there is some non-zero value when region i is connected to region j, and 0 otherwise. In addition, an approach similar to that for a random effect is used to incorporate observations belonging to specific regions. These are sometimes referred to as geoadditive models. You’ll be shocked to know that mgcv has a smooth construct for this situation as well, bs = 'mrf', where mrf stands for Markov random field, which is an undirected graph. The following67 will model the percentage of adults with only a high school education. Unfortunately, when dealing with spatial data, getting it into a format amenable to modeling will often take some work. Specifically, mgcv will need a neighborhood list to tell it how the different areas are linked68. Furthermore, the data we want to use will need to be linked to the data used for mapping. The first step is to read a shapefile that has some county level information. You could get this from census data as well69. # contiguous states c(1,4:6, 8:13, 16:42, 44:51, 53:56) library(sp) shp = rgdal::readOGR(&#39;data/us_county_hs_only&#39;) OGR data source with driver: ESRI Shapefile Source: &quot;/Users/micl/Documents/Stats/Repositories/Docs/generalized-additive-models/data/us_county_hs_only&quot;, layer: &quot;us_county_hs_only&quot; with 3233 features It has 11 fields Integer64 fields read as strings: ALAND AWATER ## select michigan, and convert % to proportion mich_df = shp[shp$STATEFP %in% c(26),] %&gt;% # add other FIPS codes as desired as_tibble() %&gt;% droplevels() %&gt;% mutate( hsd = hs_pct / 100, county = stringr::str_replace(tolower(NAME), pattern = &#39;\\\\.&#39;, &#39;&#39;), county = factor(county) ) The following creates a neighborhood list70. We also need names to match the values in the data, as well as the plotting data to be used later. I just made them lower case and remove punctuation. If you use more than one state, you will have to deal with duplicated names in some fashion. nb = spdep::poly2nb(shp[shp$STATEFP %in% c(26), ], row.names = mich_df$county) names(nb) = attr(nb, &quot;region.id&quot;) With neighborhood in place, we can now finally run the model. Note that the ID used for the smooth, in this case county, needs to be a factor variable. If not, you will get an uninformative error message that doesn’t tell you that’s the problem. For this demonstration we’ll not include any other features in the model, but normally you would include any relevant ones. gam_mrf = gam( # define MRF smooth hsd ~ s(county, bs = &#39;mrf&#39;, xt = list(nb = nb)), data = mich_df, method = &#39;REML&#39;, # fit a beta regression family = betar ) summary(gam_mrf) Family: Beta regression(103.966) Link function: logit Formula: hsd ~ s(county, bs = &quot;mrf&quot;, xt = list(nb = nb)) Parametric coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.57837 0.02237 -25.85 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Approximate significance of smooth terms: edf Ref.df Chi.sq p-value s(county) 29.75 45.58 65.33 0.0297 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 R-sq.(adj) = 0.492 Deviance explained = 67.4% -REML = -113.47 Scale est. = 1 n = 83 mich_df = mich_df %&gt;% mutate(fit = predict(gam_mrf, type = &#39;response&#39;)) Now we can plot it. Plotly works with maps package objects that have been converted via ggplot2’s map_data function. So, we create some plot-specific data, and then add our fitted values to it. We then add our own coloring based on the fitted values, and a custom clean theme. plotdat = map_data(&quot;county&quot;, &#39;michigan&#39;) %&gt;% left_join(mich_df, by = c(&#39;subregion&#39; = &#39;county&#39;)) %&gt;% mutate(fillcol = cut(fit, breaks = seq(.25, .45, by = .025))) p = plotdat %&gt;% group_by(subregion) %&gt;% plot_ly( x = ~ long, y = ~ lat, color = ~ fillcol, colors = scico::scico(100, palette = &#39;tokyo&#39;), text = ~ subregion, hoverinfo = &#39;text&#39; ) %&gt;% add_polygons(line = list(width = 0.4)) %&gt;% layout(title = &quot;% with Maximum of HS Education in Michigan&quot;) %&gt;% theme_blank() Be prepared, as this potentially will be a notable undertaking to sort out for your given situation, depending on the map objects and structure you’re dealing with. A Discrete Alternative One of the things that has puzzled me is just how often people deal with geography while ignoring what would almost always be inherent correlation in discrete geographical or other units. In the social sciences for example, one will see a standard random effects approach, i.e. a mixed model, applied in the vast majority of situations where the data comes from multiple regions. This will allow for region specific effects, which is very useful, but it won’t take advantage of the fact that the regions may be highly correlated with one another with regard to the target variable of interest, even after controlling for other aspects. We’ve already been using gamm, but haven’t been using the typical random effects approach with it. We could do so here, but we can also just stick to the usual gam function, as it has a basis option for random effects. One thing that distinguishes the mixed model setting is that observations will be clustered within the geographical units. So for our example, we’ll use the Munich rent data available from the gamlss family of packages, which contains objects for the Munich rent data and boundaries files of the corresponding districts from the 1999 survey. The rent99 data contains information about rent, year of construction, weather it has central heating, etc. Important for our purposes is the district identifier. The following shows the data structure for some observations. @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); @import url(\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #bjuosrnvrs .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: none; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #bjuosrnvrs .gt_heading { background-color: #FFFFFF; text-align: left; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bjuosrnvrs .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #bjuosrnvrs .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #bjuosrnvrs .gt_bottom_border { border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bjuosrnvrs .gt_col_headings { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bjuosrnvrs .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #bjuosrnvrs .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 12px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #bjuosrnvrs .gt_column_spanner_outer:first-child { padding-left: 0; } #bjuosrnvrs .gt_column_spanner_outer:last-child { padding-right: 0; } #bjuosrnvrs .gt_column_spanner { border-bottom-style: none; border-bottom-width: 1px; border-bottom-color: #334422; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #bjuosrnvrs .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #bjuosrnvrs .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #bjuosrnvrs .gt_from_md > :first-child { margin-top: 0; } #bjuosrnvrs .gt_from_md > :last-child { margin-bottom: 0; } #bjuosrnvrs .gt_row { padding-top: 7px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #bjuosrnvrs .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #bjuosrnvrs .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #bjuosrnvrs .gt_row_group_first td { border-top-width: 2px; } #bjuosrnvrs .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bjuosrnvrs .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #bjuosrnvrs .gt_first_summary_row.thick { border-top-width: 2px; } #bjuosrnvrs .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bjuosrnvrs .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bjuosrnvrs .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #bjuosrnvrs .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #bjuosrnvrs .gt_table_body { border-top-style: none; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #FFFFFF; } #bjuosrnvrs .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bjuosrnvrs .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #bjuosrnvrs .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bjuosrnvrs .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #bjuosrnvrs .gt_left { text-align: left; } #bjuosrnvrs .gt_center { text-align: center; } #bjuosrnvrs .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #bjuosrnvrs .gt_font_normal { font-weight: normal; } #bjuosrnvrs .gt_font_bold { font-weight: bold; } #bjuosrnvrs .gt_font_italic { font-style: italic; } #bjuosrnvrs .gt_super { font-size: 65%; } #bjuosrnvrs .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #bjuosrnvrs .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #bjuosrnvrs .gt_asterisk { font-size: 100%; vertical-align: 0; } #bjuosrnvrs .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #bjuosrnvrs .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #bjuosrnvrs .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } rent rentsqm area yearc location bath kitchen cheating district 109.95 4.23 26.00 1,918.00 2 0 0 0 916.00 243.28 8.69 28.00 1,918.00 2 0 0 1 813.00 261.64 8.72 30.00 1,918.00 1 0 0 1 611.00 106.41 3.55 30.00 1,918.00 2 0 0 0 2,025.00 133.38 4.45 30.00 1,918.00 2 0 0 1 561.00 339.03 11.30 30.00 1,918.00 2 0 0 1 541.00 215.23 6.94 31.00 1,918.00 1 0 0 0 822.00 323.23 10.43 31.00 1,918.00 1 0 1 1 1,713.00 216.31 6.76 32.00 1,918.00 1 0 0 0 1,812.00 245.28 7.43 33.00 1,918.00 2 0 0 0 152.00 285.38 8.39 34.00 1,918.00 2 0 0 0 943.00 238.31 6.81 35.00 1,918.00 1 0 0 1 1,711.00 374.46 10.70 35.00 1,918.00 2 0 0 1 231.00 137.95 3.83 36.00 1,918.00 2 0 0 1 411.00 188.36 4.96 38.00 1,918.00 1 0 0 0 1,711.00 Here again we’ll use a Markov random field smooth, and for comparison a mixed model with a random effect for district. The plots show that, while close, they don’t exactly come to the same conclusions for the district fitted values. library(gamlss.data) # prep data rent99 = rent99 %&gt;% mutate(district = factor(district)) rent99.polys[!names(rent99.polys) %in% levels(rent99$district)] = NULL # run mrf and re models gam_rent_mrf = gam(rent ~ s(district, bs = &#39;mrf&#39;, xt = list(polys = rent99.polys)), data = rent99, method = &#39;REML&#39;) gam_rent_re = gam(rent ~ s(district, bs = &#39;re&#39;), data = rent99, method = &#39;REML&#39;) Next we show the plot of the estimated random effects of both models on the map of districts71. Gaps appear because there isn’t data for every district available, as some are districts without houses like parks, industrial areas, etc. As we might have expected, there appears to be more color coordination with the MRF result (left), since neighbors are more likely to be similar. Meanwhile, the mixed model approach, while showing similar patterning, does nothing inherently to correlate one district with the ones it’s next to, but may allow for more regularization. Either of these models is appropriate, but they ask different questions. The MRF approach may produce better results since it takes into account the potential similarity among neighbors, but also may not be necessary if there isn’t much similarity among geographical units. One should also think about whether the other features in the model may account spatial autocorrelation or not, or unspecified unit effects, and proceed accordingly. In addition, there are approaches that would allow for a mix of both the unstructured and spatial random effects. See Riebler et al. (2016) and the brms package and Mitzi Morris’ note here . References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
